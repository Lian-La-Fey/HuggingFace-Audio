{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Automatic speech recognition with a pipeline\n\nOtomatik Konuşma Tanıma (ASR), konuşma ses kaydının metne dönüştürülmesini içeren bir görevdir. Bu görevin, videolar için altyazı oluşturmaktan Siri ve Alexa gibi sanal asistanlar için sesli komutları etkinleştirmeye kadar çok sayıda pratik uygulaması vardır.\n\nBu bölümde, daha önce olduğu gibi aynı MINDS-14 veri kümesini kullanarak fatura ödeme hakkında soru soran bir kişinin ses kaydını yazıya dökmek için otomatik konuşma tanıma işlem hattını kullanacağız.\n\nBaşlamak için, veri kümesini yükleyin ve henüz yapmadıysanız, bir işlem hattı ile ses sınıflandırma bölümünde açıklandığı gibi 16kHz'e yükseltin.\n\nBir ses kaydını yazıya dökmek için Transformers'daki otomatik konuşma tanıma pipeline'ını kullanabiliriz.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"from datasets import load_dataset, Audio\n\nminds = load_dataset(\n    \"PolyAI/minds14\", name=\"en-AU\", \n    split=\"train\", trust_remote_code=True,\n)\n\nminds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))\nminds","metadata":{"execution":{"iopub.status.busy":"2024-08-08T07:27:28.849184Z","iopub.execute_input":"2024-08-08T07:27:28.849560Z","iopub.status.idle":"2024-08-08T07:27:50.575349Z","shell.execute_reply.started":"2024-08-08T07:27:28.849528Z","shell.execute_reply":"2024-08-08T07:27:50.574131Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.90k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d0e212f1c114eef971d468a58b43c7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/5.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11aa155d5740402cb1a4e713872fc223"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bcc1abf077c4a57a1fe3210e8eb9cc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc686727fb154bd385e69a20dc2c9b8d"}},"metadata":{}},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n    num_rows: 654\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\n\nasr = pipeline(\"automatic-speech-recognition\")","metadata":{"execution":{"iopub.status.busy":"2024-08-08T07:27:50.581162Z","iopub.execute_input":"2024-08-08T07:27:50.581521Z","iopub.status.idle":"2024-08-08T07:28:16.253075Z","shell.execute_reply.started":"2024-08-08T07:27:50.581493Z","shell.execute_reply":"2024-08-08T07:28:16.251821Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-08 07:27:58.675165: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-08 07:27:58.675337: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-08 07:27:58.915200: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nNo model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 55bb623 (https://huggingface.co/facebook/wav2vec2-base-960h).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fddefc7d5ae641f9b1f9e97a87a27faf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df9dfecaf5254490ab77d76ad2c07b79"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdf68a7818464570b4a6eeeb5cff7515"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f475ba0a8cf641b3ad3b65041f377a79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49622d1a381a42028ec2d989a5790569"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6c81fbed05a4f459d97d6f48292b19e"}},"metadata":{}}]},{"cell_type":"code","source":"example = minds[0]\nasr(example[\"audio\"][\"array\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-08T07:28:16.255759Z","iopub.execute_input":"2024-08-08T07:28:16.256699Z","iopub.status.idle":"2024-08-08T07:28:34.950700Z","shell.execute_reply.started":"2024-08-08T07:28:16.256656Z","shell.execute_reply":"2024-08-08T07:28:34.949429Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'text': 'I WOULD LIKE TO PAY MY ELECTRICITY BILL USING MY CAD CAN YOU PLEASE ASSIST'}"},"metadata":{}}]},{"cell_type":"code","source":"example[\"english_transcription\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-08T07:28:47.653363Z","iopub.execute_input":"2024-08-08T07:28:47.654905Z","iopub.status.idle":"2024-08-08T07:28:47.661520Z","shell.execute_reply.started":"2024-08-08T07:28:47.654863Z","shell.execute_reply":"2024-08-08T07:28:47.660152Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'I would like to pay my electricity bill using my card can you please assist'"},"metadata":{}}]},{"cell_type":"markdown","source":"Model, sesin transkripsiyonunda oldukça iyi bir iş çıkarmış gibi görünüyor! Orijinal transkripsiyona kıyasla yalnızca bir kelimeyi (\"card\") yanlış yazmış ki bu da konuşmacının \"r\" harfinin genellikle sessiz olduğu bir Avustralya aksanına sahip olduğu düşünüldüğünde oldukça iyi.\n\nVarsayılan olarak, bu işlem hattı İngilizce dili için otomatik konuşma tanıma için eğitilmiş bir model kullanır, bu da bu örnek için uygundur. MINDS-14'ün diğer alt kümelerini farklı bir dilde yazıya dökmeyi denemek isterseniz, Hub'da önceden eğitilmiş bir ASR modeli bulabilirsiniz. Modeller listesini önce göreve, ardından dile göre filtreleyebilirsiniz. Beğendiğiniz modeli bulduğunuzda, modelin adını boru hattına model bağımsız değişkeni olarak aktarın.\n\nBunu MINDS-14'ün Almanca bölümü için deneyelim. \"de-DE\" alt kümesini yükleyin:","metadata":{}},{"cell_type":"code","source":"minds = load_dataset(\"PolyAI/minds14\", name=\"de-DE\", split=\"train\")\nminds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))\nminds","metadata":{"execution":{"iopub.status.busy":"2024-08-08T07:33:55.942670Z","iopub.execute_input":"2024-08-08T07:33:55.943127Z","iopub.status.idle":"2024-08-08T07:33:57.423334Z","shell.execute_reply.started":"2024-08-08T07:33:55.943095Z","shell.execute_reply":"2024-08-08T07:33:57.422047Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d15f83c27d5545b798094891ac48a4e8"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n    num_rows: 611\n})"},"metadata":{}}]},{"cell_type":"code","source":"example = minds[0]\nexample[\"transcription\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-08T07:34:06.302079Z","iopub.execute_input":"2024-08-08T07:34:06.302587Z","iopub.status.idle":"2024-08-08T07:34:06.321148Z","shell.execute_reply.started":"2024-08-08T07:34:06.302547Z","shell.execute_reply":"2024-08-08T07:34:06.319234Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'ich möchte gerne Geld auf mein Konto einzahlen'"},"metadata":{}}]},{"cell_type":"code","source":"asr = pipeline(\"automatic-speech-recognition\", model=\"maxidl/wav2vec2-large-xlsr-german\")\nasr(example[\"audio\"][\"array\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-08T07:34:30.825089Z","iopub.execute_input":"2024-08-08T07:34:30.825491Z","iopub.status.idle":"2024-08-08T07:34:41.125119Z","shell.execute_reply.started":"2024-08-08T07:34:30.825456Z","shell.execute_reply":"2024-08-08T07:34:41.123794Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e779917c7ec46c4b8d86e3c389cc184"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fb2b58d3d674e0b937abbad54937086"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of the model checkpoint at maxidl/wav2vec2-large-xlsr-german were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at maxidl/wav2vec2-large-xlsr-german and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31b6a3044e9e4ee09b69f2f858673741"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7afd99d8e4194660b471b2e189ed9d41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d52a242621a49fe82e4df4d7cdafafd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/158 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fe477f47c8a42b0a95a10a1021021e2"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'text': 'ich möchte gerne geld auf mein konto einzallen'}"},"metadata":{}}]},{"cell_type":"markdown","source":"Kendi görevinizi çözmeye çalışırken, bu ünitede gösterdiğimiz gibi basit bir boru hattı ile başlamak, çeşitli avantajlar sunan değerli bir araçtır:\n\n- Görevinizi gerçekten iyi çözen önceden eğitilmiş bir model mevcut olabilir, bu da size bolca zaman kazandırır\n- pipeline() sizin için tüm ön/son işlemlerle ilgilenir, böylece verileri bir model için doğru biçime getirme konusunda endişelenmenize gerek kalmaz\n- Sonuç ideal olmasa da, bu size ileride ince ayar yapmak için hızlı bir temel sağlar\n- Özel verileriniz üzerinde bir model üzerinde ince ayar yapıp Hub'da paylaştığınızda, tüm topluluk pipeline() yöntemi aracılığıyla bunu hızlı ve zahmetsiz bir şekilde kullanabilecek ve yapay zeka daha erişilebilir hale gelecektir.","metadata":{}}]}