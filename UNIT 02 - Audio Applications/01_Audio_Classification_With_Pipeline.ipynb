{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Audio classification with a pipeline\n\nSes sınıflandırması, içeriğine göre bir ses kaydına bir veya daha fazla etiket atanmasını içerir. Bu etiketler müzik, konuşma veya gürültü gibi farklı ses kategorilerine ya da kuş sesi veya araba motoru sesi gibi daha spesifik kategorilere karşılık gelebilir.\n\nEn popüler ses dönüştürücülerinin nasıl çalıştığına dair ayrıntılara girmeden ve özel bir modele ince ayar yapmadan önce, Transformers ile yalnızca birkaç satır kodla ses sınıflandırması için kullanıma hazır önceden eğitilmiş bir modeli nasıl kullanabileceğinizi görelim.\n\nDevam edelim ve önceki ünitede keşfettiğiniz MmINDS-14 veri kümesini kullanalım. Hatırlarsanız, MINDS-14 bir e-bankacılık sistemine çeşitli dil ve lehçelerde sorular soran kişilerin kayıtlarını içeriyor ve her kayıt için intent_class değerine sahip. Kayıtları aramanın amacına göre sınıflandırabiliriz.\n\nDaha önce olduğu gibi, boru hattını denemek için verilerin en-AU alt kümesini yükleyerek başlayalım ve çoğu konuşma modelinin gerektirdiği 16kHz örnekleme oranına yükseltelim.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"from datasets import load_dataset, Audio\n\nminds = load_dataset(\n    \"PolyAI/minds14\", name=\"en-AU\", \n    split=\"train\", trust_remote_code=True,\n)\nminds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))\nminds","metadata":{"execution":{"iopub.status.busy":"2024-08-08T06:37:05.572637Z","iopub.execute_input":"2024-08-08T06:37:05.573000Z","iopub.status.idle":"2024-08-08T06:37:28.114612Z","shell.execute_reply.started":"2024-08-08T06:37:05.572970Z","shell.execute_reply":"2024-08-08T06:37:28.113520Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.90k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a16f20a89cc9435b93eb982471a55133"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/5.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9467f87b724c4db1bf66fdc5da704194"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88069d13e52f4c97934924993e80db08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f392c7e3996043308d2a32f52ebc3ed2"}},"metadata":{}},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n    num_rows: 654\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"Bir ses kaydını bir dizi sınıfa ayırmak için Transformers'ın ses sınıflandırma pipeline'ını kullanabiliriz. Bizim durumumuzda, amaç sınıflandırması için ve özellikle MINDS-14 veri kümesi üzerinde ince ayar yapılmış bir modele ihtiyacımız var. Neyse ki Hub'da tam da bunu yapan bir model var! Pipeline() fonksiyonunu kullanarak yükleyelim:","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nclassifier = pipeline(\n    task=\"audio-classification\",\n    model=\"anton-l/xtreme_s_xlsr_300m_minds14\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T06:37:28.116271Z","iopub.execute_input":"2024-08-08T06:37:28.116586Z","iopub.status.idle":"2024-08-08T06:38:48.691744Z","shell.execute_reply.started":"2024-08-08T06:37:28.116560Z","shell.execute_reply":"2024-08-08T06:38:48.690678Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-08 06:37:34.421611: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-08 06:37:34.421838: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-08 06:37:34.575856: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.73k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ae9349b584f4a7ca2d2772e7c04f49d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef61d1b35f7b48e8bddc0c0301444b9d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of the model checkpoint at anton-l/xtreme_s_xlsr_300m_minds14 were not used when initializing Wav2Vec2ForSequenceClassification: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at anton-l/xtreme_s_xlsr_300m_minds14 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"892c25ecd26e4a4aa83a370adb7cf805"}},"metadata":{}}]},{"cell_type":"code","source":"example = minds[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-08T06:38:48.693367Z","iopub.execute_input":"2024-08-08T06:38:48.693970Z","iopub.status.idle":"2024-08-08T06:39:06.085937Z","shell.execute_reply.started":"2024-08-08T06:38:48.693942Z","shell.execute_reply":"2024-08-08T06:39:06.084866Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"classifier(example[\"audio\"][\"array\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-08T06:39:06.087980Z","iopub.execute_input":"2024-08-08T06:39:06.088750Z","iopub.status.idle":"2024-08-08T06:39:09.117464Z","shell.execute_reply.started":"2024-08-08T06:39:06.088711Z","shell.execute_reply":"2024-08-08T06:39:09.116418Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.9625310301780701, 'label': 'pay_bill'},\n {'score': 0.02867276780307293, 'label': 'freeze'},\n {'score': 0.003349797334522009, 'label': 'card_issues'},\n {'score': 0.002005803631618619, 'label': 'abroad'},\n {'score': 0.000848432769998908, 'label': 'high_value_payment'}]"},"metadata":{}}]},{"cell_type":"code","source":"id2label = minds.features[\"intent_class\"].int2str\nid2label(example[\"intent_class\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-08T06:39:09.118822Z","iopub.execute_input":"2024-08-08T06:39:09.119169Z","iopub.status.idle":"2024-08-08T06:39:09.126227Z","shell.execute_reply.started":"2024-08-08T06:39:09.119141Z","shell.execute_reply":"2024-08-08T06:39:09.125211Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'pay_bill'"},"metadata":{}}]}]}