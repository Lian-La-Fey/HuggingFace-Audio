{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hands-on exercise\n\nBu ünitede, yeni bir dilde Whisper gibi bir modele (küçük bir kontrol noktası bile olsa) ince ayar yapmak için gereken zaman ve kaynakları kabul ederek ASR modellerine ince ayar yapmanın zorluklarını araştırdık. Uygulamalı bir deneyim sağlamak için, daha küçük bir veri kümesi kullanırken bir ASR modeline ince ayar yapma sürecinde gezinmenizi sağlayan bir alıştırma tasarladık. Bu alıştırmanın temel amacı, üretim düzeyinde sonuçlar beklemek yerine sizi sürece alıştırmaktır. Sınırlı kaynaklarla bile bunu başarabilmenizi sağlamak için kasıtlı olarak düşük bir metrik belirledik.\n\nİşte talimatlar:\n\n- \"PolyAI/minds14\" veri kümesinin Amerikan İngilizcesi (\"en-US\") alt kümesini kullanarak \"openai/whisper-tiny\" modeline ince ayar yapın. \n\n- Eğitim için ilk 450 örneği ve değerlendirme için geri kalanını kullanın. .map yöntemini kullanarak veri kümesini ön işleme tabi tutarken num_proc=1 olarak ayarladığınızdan emin olun (bu, modelinizin değerlendirme için doğru şekilde gönderilmesini sağlayacaktır). \n\n- Modeli değerlendirmek için, bu Ünitede açıklandığı gibi wer ve wer_ortho metriklerini kullanın. Ancak, metriği 100 ile çarparak yüzdelere dönüştürmeyin (Örneğin, WER %42 ise, bu alıştırmada 0,42 değerini görmeyi bekleyeceğiz).\n\n\nBir modele ince ayar yaptıktan sonra, aşağıdaki kwargs ile Hub'a yüklediğinizden emin olun:\n```\nkwargs = {\n     \"dataset_tags\": \"PolyAI/minds14\",\n    \"finetuned_from\": \"openai/whisper-tiny\",\n    \"tasks\": \"automatic-speech-recognition\",\n}\n```\n\nModelinizin normalleştirilmiş WER (wer) değeri 0,37'den düşükse bu ödevi geçeceksiniz.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", trust_remote_code=True)\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:31:46.909378Z","iopub.execute_input":"2024-08-15T11:31:46.909746Z","iopub.status.idle":"2024-08-15T11:32:07.546396Z","shell.execute_reply.started":"2024-08-15T11:31:46.909715Z","shell.execute_reply":"2024-08-15T11:32:07.545573Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.90k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24004044042c47b281f783f36b4f2f43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/5.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f37a9cd08564de893733e63ccbd5a6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30cde6c8bc5448089ff2df36c86ed1c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26bfb020119d473daaed59a3127d939c"}},"metadata":{}},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n        num_rows: 563\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset = dataset[\"train\"].train_test_split(train_size=450)\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:07.547816Z","iopub.execute_input":"2024-08-15T11:32:07.548091Z","iopub.status.idle":"2024-08-15T11:32:07.564661Z","shell.execute_reply.started":"2024-08-15T11:32:07.548068Z","shell.execute_reply":"2024-08-15T11:32:07.563751Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n        num_rows: 450\n    })\n    test: Dataset({\n        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n        num_rows: 113\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:07.565781Z","iopub.execute_input":"2024-08-15T11:32:07.566176Z","iopub.status.idle":"2024-08-15T11:32:20.447381Z","shell.execute_reply.started":"2024-08-15T11:32:07.566147Z","shell.execute_reply":"2024-08-15T11:32:20.446432Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'path': '/root/.cache/huggingface/datasets/downloads/extracted/28aa727f91fee90575c34956bab09d1716cfaf460c6afcba86a10f04a7d58b83/en-US~PAY_BILL/602bae7bbb1e6d0fbce92264.wav',\n 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/28aa727f91fee90575c34956bab09d1716cfaf460c6afcba86a10f04a7d58b83/en-US~PAY_BILL/602bae7bbb1e6d0fbce92264.wav',\n  'array': array([-0.00024414,  0.        , -0.00024414, ..., -0.00024414,\n          0.        ,  0.        ]),\n  'sampling_rate': 8000},\n 'transcription': \"I'd like to make a payment\",\n 'english_transcription': \"I'd like to make a payment\",\n 'intent_class': 13,\n 'lang_id': 4}"},"metadata":{}}]},{"cell_type":"code","source":"dataset = dataset.select_columns([\"audio\", \"transcription\"])\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:20.449964Z","iopub.execute_input":"2024-08-15T11:32:20.450595Z","iopub.status.idle":"2024-08-15T11:32:20.461561Z","shell.execute_reply.started":"2024-08-15T11:32:20.450569Z","shell.execute_reply":"2024-08-15T11:32:20.460633Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['audio', 'transcription'],\n        num_rows: 450\n    })\n    test: Dataset({\n        features: ['audio', 'transcription'],\n        num_rows: 113\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import WhisperProcessor\n\nprocessor = WhisperProcessor.from_pretrained(\n    \"openai/whisper-tiny\", language=\"english\", task=\"transcribe\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:20.462606Z","iopub.execute_input":"2024-08-15T11:32:20.462894Z","iopub.status.idle":"2024-08-15T11:32:26.860295Z","shell.execute_reply.started":"2024-08-15T11:32:20.462870Z","shell.execute_reply":"2024-08-15T11:32:26.859286Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4a8ecf9a2e74698b906c67ca9f1b0bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54b105d4a87d431388fab0ca4bcb00ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed8c41c308df44cd95fce45c5340c641"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d820cf50e91472986f3cf7489c59054"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4767a2b7c6d47ee8be44ca254d5e118"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b84481f6da7241ce809ae59bc1924d3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c39b1541bb694a7fa93e84a9f432cc9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30c3a4f7ce384379898bf784b57e7f9d"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset[\"train\"].features","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:26.861496Z","iopub.execute_input":"2024-08-15T11:32:26.862000Z","iopub.status.idle":"2024-08-15T11:32:26.868361Z","shell.execute_reply.started":"2024-08-15T11:32:26.861973Z","shell.execute_reply":"2024-08-15T11:32:26.867505Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'audio': Audio(sampling_rate=8000, mono=True, decode=True, id=None),\n 'transcription': Value(dtype='string', id=None)}"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Audio\n\nsampling_rate = processor.feature_extractor.sampling_rate\ndataset = dataset.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))\ndataset[\"train\"].features","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:26.869671Z","iopub.execute_input":"2024-08-15T11:32:26.869970Z","iopub.status.idle":"2024-08-15T11:32:26.887049Z","shell.execute_reply.started":"2024-08-15T11:32:26.869946Z","shell.execute_reply":"2024-08-15T11:32:26.886198Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'audio': Audio(sampling_rate=16000, mono=True, decode=True, id=None),\n 'transcription': Value(dtype='string', id=None)}"},"metadata":{}}]},{"cell_type":"code","source":"def prepare_dataset(example):\n    audio = example[\"audio\"]\n\n    example = processor(\n        audio=audio[\"array\"],\n        sampling_rate=audio[\"sampling_rate\"],\n        text=example[\"transcription\"],\n    )\n    \n    example[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:26.888618Z","iopub.execute_input":"2024-08-15T11:32:26.889038Z","iopub.status.idle":"2024-08-15T11:32:26.897307Z","shell.execute_reply.started":"2024-08-15T11:32:26.889005Z","shell.execute_reply":"2024-08-15T11:32:26.896578Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(\n    prepare_dataset, remove_columns=dataset.column_names[\"train\"], num_proc=1\n)\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:26.898327Z","iopub.execute_input":"2024-08-15T11:32:26.898718Z","iopub.status.idle":"2024-08-15T11:32:54.814871Z","shell.execute_reply.started":"2024-08-15T11:32:26.898669Z","shell.execute_reply":"2024-08-15T11:32:54.813935Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/450 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3cadd22c0d1407c97e4970a5bb6aa8b"}},"metadata":{}},{"name":"stderr","text":"2024-08-15 11:32:31.044284: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-15 11:32:31.044386: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-15 11:32:31.164483: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab2987b70eba45e8b27eccf5c855fd7c"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_features', 'labels', 'input_length'],\n        num_rows: 450\n    })\n    test: Dataset({\n        features: ['input_features', 'labels', 'input_length'],\n        num_rows: 113\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 30.0\n\ndef is_audio_in_length_range(length):\n    return length < max_input_length\n\ndataset[\"train\"] = dataset[\"train\"].filter(\n    is_audio_in_length_range,\n    input_columns=[\"input_length\"],\n)\n\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:54.819089Z","iopub.execute_input":"2024-08-15T11:32:54.819817Z","iopub.status.idle":"2024-08-15T11:32:54.852265Z","shell.execute_reply.started":"2024-08-15T11:32:54.819789Z","shell.execute_reply":"2024-08-15T11:32:54.851426Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/450 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd7fb231e26b43c6912b21ac7c5415c7"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_features', 'labels', 'input_length'],\n        num_rows: 447\n    })\n    test: Dataset({\n        features: ['input_features', 'labels', 'input_length'],\n        num_rows: 113\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\n\n@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n    \n    def __call__(\n        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]\n    ) -> Dict[str, torch.Tensor]:\n        input_features = [\n            {\"input_features\": feature[\"input_features\"][0]} for feature in features\n        ]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n        labels = labels_batch[\"input_ids\"].masked_fill(\n            labels_batch.attention_mask.ne(1), -100\n        )\n        \n        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n        \n        batch[\"labels\"] = labels\n        \n        return batch","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:54.853410Z","iopub.execute_input":"2024-08-15T11:32:54.853681Z","iopub.status.idle":"2024-08-15T11:32:55.200921Z","shell.execute_reply.started":"2024-08-15T11:32:54.853658Z","shell.execute_reply":"2024-08-15T11:32:55.199932Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:55.202077Z","iopub.execute_input":"2024-08-15T11:32:55.202364Z","iopub.status.idle":"2024-08-15T11:32:55.214053Z","shell.execute_reply.started":"2024-08-15T11:32:55.202340Z","shell.execute_reply":"2024-08-15T11:32:55.213241Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"!pip install -q evaluate jiwer","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:55.214981Z","iopub.execute_input":"2024-08-15T11:32:55.215228Z","iopub.status.idle":"2024-08-15T11:33:10.633689Z","shell.execute_reply.started":"2024-08-15T11:32:55.215206Z","shell.execute_reply":"2024-08-15T11:33:10.632725Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\nfrom transformers.models.whisper.english_normalizer import BasicTextNormalizer\n\n\nmetric = evaluate.load(\"wer\")\nnormalizer = BasicTextNormalizer()\n\ndef compute_metrics(pred):\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n    \n    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n    \n    wer_ortho = metric.compute(predictions=pred_str, references=label_str)\n    \n    pred_str_norm = [normalizer(pred) for pred in pred_str]\n    label_str_norm = [normalizer(label) for label in label_str]\n    \n    pred_str_norm = [\n        pred_str_norm[i] for i in range(len(pred_str_norm)) if len(label_str_norm[i]) > 0\n    ]\n    label_str_norm = [\n        label_str_norm[i]\n        for i in range(len(label_str_norm))\n        if len(label_str_norm[i]) > 0\n    ]\n    \n    wer = metric.compute(predictions=pred_str_norm, references=label_str_norm)\n\n    return {\"wer_ortho\": wer_ortho, \"wer\": wer}","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:33:10.635330Z","iopub.execute_input":"2024-08-15T11:33:10.635730Z","iopub.status.idle":"2024-08-15T11:33:11.571448Z","shell.execute_reply.started":"2024-08-15T11:33:10.635681Z","shell.execute_reply":"2024-08-15T11:33:11.570462Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d484896ff0a46e1bf3d6c1295db6ef8"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import WhisperForConditionalGeneration\n\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:33:11.572404Z","iopub.execute_input":"2024-08-15T11:33:11.572683Z","iopub.status.idle":"2024-08-15T11:33:14.318087Z","shell.execute_reply.started":"2024-08-15T11:33:11.572658Z","shell.execute_reply":"2024-08-15T11:33:14.317020Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14d8a72ef2df48c1abe2541e7d69f8ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/151M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d345bd71c582460c81600f57b91772a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/3.75k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14b67a8e365e4e8dbfefafe72565c384"}},"metadata":{}}]},{"cell_type":"code","source":"from functools import partial\n\n# gradyan kontrol noktası ile uyumsuz olduğu için eğitim sırasında önbelleği devre dışı bırakın\nmodel.config.use_cache = False\n\n# üretim için dili ve görevi ayarlayın ve önbelleği yeniden etkinleştirin\nmodel.generate = partial(\n    model.generate, language=\"english\", task=\"transcribe\", use_cache=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:33:14.319260Z","iopub.execute_input":"2024-08-15T11:33:14.319519Z","iopub.status.idle":"2024-08-15T11:33:14.324331Z","shell.execute_reply.started":"2024-08-15T11:33:14.319496Z","shell.execute_reply":"2024-08-15T11:33:14.323440Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./whisper-tiny-en\",\n    per_device_train_batch_size=8,\n    gradient_accumulation_steps=4,\n    learning_rate=1e-5,\n    lr_scheduler_type=\"constant_with_warmup\",\n    warmup_steps=50,\n    max_steps=200,\n    gradient_checkpointing=True,\n    fp16=True,\n    fp16_full_eval=True,\n    evaluation_strategy=\"steps\",\n    per_device_eval_batch_size=8,\n    predict_with_generate=True,\n    generation_max_length=225,\n    save_steps=100,\n    eval_steps=100,\n    logging_steps=50,\n    report_to=[\"tensorboard\"],\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:33:14.325535Z","iopub.execute_input":"2024-08-15T11:33:14.325828Z","iopub.status.idle":"2024-08-15T11:33:14.418229Z","shell.execute_reply.started":"2024-08-15T11:33:14.325805Z","shell.execute_reply":"2024-08-15T11:33:14.417266Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:33:14.419332Z","iopub.execute_input":"2024-08-15T11:33:14.419606Z","iopub.status.idle":"2024-08-15T11:33:14.444355Z","shell.execute_reply.started":"2024-08-15T11:33:14.419584Z","shell.execute_reply":"2024-08-15T11:33:14.443500Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0a246412a7c43b4a300b919120e0923"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=processor,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:35:17.705588Z","iopub.execute_input":"2024-08-15T11:35:17.706190Z","iopub.status.idle":"2024-08-15T11:35:18.695821Z","shell.execute_reply.started":"2024-08-15T11:35:17.706144Z","shell.execute_reply":"2024-08-15T11:35:18.694914Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:35:20.299589Z","iopub.execute_input":"2024-08-15T11:35:20.299967Z","iopub.status.idle":"2024-08-15T11:59:44.721482Z","shell.execute_reply.started":"2024-08-15T11:35:20.299936Z","shell.execute_reply":"2024-08-15T11:59:44.720472Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 24:07, Epoch 14/15]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Wer Ortho</th>\n      <th>Wer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.241900</td>\n      <td>0.486529</td>\n      <td>0.294230</td>\n      <td>0.286589</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.004800</td>\n      <td>0.594461</td>\n      <td>0.289791</td>\n      <td>0.289039</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\nThere were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=0.6235875126719475, metrics={'train_runtime': 1457.0057, 'train_samples_per_second': 4.393, 'train_steps_per_second': 0.137, 'total_flos': 1.5721620037632e+17, 'train_loss': 0.6235875126719475, 'epoch': 14.285714285714286})"},"metadata":{}}]},{"cell_type":"code","source":"kwargs = {\n     \"dataset_tags\": \"PolyAI/minds14\",\n    \"finetuned_from\": \"openai/whisper-tiny\",\n    \"tasks\": \"automatic-speech-recognition\",\n}\n\ntrainer.push_to_hub(**kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:59:44.723326Z","iopub.execute_input":"2024-08-15T11:59:44.724002Z","iopub.status.idle":"2024-08-15T11:59:47.994326Z","shell.execute_reply.started":"2024-08-15T11:59:44.723966Z","shell.execute_reply":"2024-08-15T11:59:47.993377Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Leotrim/whisper-tiny-en/commit/fb8c546f0b68c6f9adb3d70a5beba825171d3a7b', commit_message='End of training', commit_description='', oid='fb8c546f0b68c6f9adb3d70a5beba825171d3a7b', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}