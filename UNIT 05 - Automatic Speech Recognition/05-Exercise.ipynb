{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hands-on exercise\n\nBu Ã¼nitede, yeni bir dilde Whisper gibi bir modele (kÃ¼Ã§Ã¼k bir kontrol noktasÄ± bile olsa) ince ayar yapmak iÃ§in gereken zaman ve kaynaklarÄ± kabul ederek ASR modellerine ince ayar yapmanÄ±n zorluklarÄ±nÄ± araÅŸtÄ±rdÄ±k. UygulamalÄ± bir deneyim saÄŸlamak iÃ§in, daha kÃ¼Ã§Ã¼k bir veri kÃ¼mesi kullanÄ±rken bir ASR modeline ince ayar yapma sÃ¼recinde gezinmenizi saÄŸlayan bir alÄ±ÅŸtÄ±rma tasarladÄ±k. Bu alÄ±ÅŸtÄ±rmanÄ±n temel amacÄ±, Ã¼retim dÃ¼zeyinde sonuÃ§lar beklemek yerine sizi sÃ¼rece alÄ±ÅŸtÄ±rmaktÄ±r. SÄ±nÄ±rlÄ± kaynaklarla bile bunu baÅŸarabilmenizi saÄŸlamak iÃ§in kasÄ±tlÄ± olarak dÃ¼ÅŸÃ¼k bir metrik belirledik.\n\nÄ°ÅŸte talimatlar:\n\n- \"PolyAI/minds14\" veri kÃ¼mesinin Amerikan Ä°ngilizcesi (\"en-US\") alt kÃ¼mesini kullanarak \"openai/whisper-tiny\" modeline ince ayar yapÄ±n. \n\n- EÄŸitim iÃ§in ilk 450 Ã¶rneÄŸi ve deÄŸerlendirme iÃ§in geri kalanÄ±nÄ± kullanÄ±n. .map yÃ¶ntemini kullanarak veri kÃ¼mesini Ã¶n iÅŸleme tabi tutarken num_proc=1 olarak ayarladÄ±ÄŸÄ±nÄ±zdan emin olun (bu, modelinizin deÄŸerlendirme iÃ§in doÄŸru ÅŸekilde gÃ¶nderilmesini saÄŸlayacaktÄ±r). \n\n- Modeli deÄŸerlendirmek iÃ§in, bu Ãœnitede aÃ§Ä±klandÄ±ÄŸÄ± gibi wer ve wer_ortho metriklerini kullanÄ±n. Ancak, metriÄŸi 100 ile Ã§arparak yÃ¼zdelere dÃ¶nÃ¼ÅŸtÃ¼rmeyin (Ã–rneÄŸin, WER %42 ise, bu alÄ±ÅŸtÄ±rmada 0,42 deÄŸerini gÃ¶rmeyi bekleyeceÄŸiz).\n\n\nBir modele ince ayar yaptÄ±ktan sonra, aÅŸaÄŸÄ±daki kwargs ile Hub'a yÃ¼klediÄŸinizden emin olun:\n```\nkwargs = {\n     \"dataset_tags\": \"PolyAI/minds14\",\n    \"finetuned_from\": \"openai/whisper-tiny\",\n    \"tasks\": \"automatic-speech-recognition\",\n}\n```\n\nModelinizin normalleÅŸtirilmiÅŸ WER (wer) deÄŸeri 0,37'den dÃ¼ÅŸÃ¼kse bu Ã¶devi geÃ§eceksiniz.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", trust_remote_code=True)\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:31:46.909378Z","iopub.execute_input":"2024-08-15T11:31:46.909746Z","iopub.status.idle":"2024-08-15T11:32:07.546396Z","shell.execute_reply.started":"2024-08-15T11:31:46.909715Z","shell.execute_reply":"2024-08-15T11:32:07.545573Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.90k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24004044042c47b281f783f36b4f2f43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/5.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f37a9cd08564de893733e63ccbd5a6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30cde6c8bc5448089ff2df36c86ed1c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26bfb020119d473daaed59a3127d939c"}},"metadata":{}},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n        num_rows: 563\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset = dataset[\"train\"].train_test_split(train_size=450)\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:07.547816Z","iopub.execute_input":"2024-08-15T11:32:07.548091Z","iopub.status.idle":"2024-08-15T11:32:07.564661Z","shell.execute_reply.started":"2024-08-15T11:32:07.548068Z","shell.execute_reply":"2024-08-15T11:32:07.563751Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n        num_rows: 450\n    })\n    test: Dataset({\n        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n        num_rows: 113\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:07.565781Z","iopub.execute_input":"2024-08-15T11:32:07.566176Z","iopub.status.idle":"2024-08-15T11:32:20.447381Z","shell.execute_reply.started":"2024-08-15T11:32:07.566147Z","shell.execute_reply":"2024-08-15T11:32:20.446432Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'path': '/root/.cache/huggingface/datasets/downloads/extracted/28aa727f91fee90575c34956bab09d1716cfaf460c6afcba86a10f04a7d58b83/en-US~PAY_BILL/602bae7bbb1e6d0fbce92264.wav',\n 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/28aa727f91fee90575c34956bab09d1716cfaf460c6afcba86a10f04a7d58b83/en-US~PAY_BILL/602bae7bbb1e6d0fbce92264.wav',\n  'array': array([-0.00024414,  0.        , -0.00024414, ..., -0.00024414,\n          0.        ,  0.        ]),\n  'sampling_rate': 8000},\n 'transcription': \"I'd like to make a payment\",\n 'english_transcription': \"I'd like to make a payment\",\n 'intent_class': 13,\n 'lang_id': 4}"},"metadata":{}}]},{"cell_type":"code","source":"dataset = dataset.select_columns([\"audio\", \"transcription\"])\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:20.449964Z","iopub.execute_input":"2024-08-15T11:32:20.450595Z","iopub.status.idle":"2024-08-15T11:32:20.461561Z","shell.execute_reply.started":"2024-08-15T11:32:20.450569Z","shell.execute_reply":"2024-08-15T11:32:20.460633Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['audio', 'transcription'],\n        num_rows: 450\n    })\n    test: Dataset({\n        features: ['audio', 'transcription'],\n        num_rows: 113\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import WhisperProcessor\n\nprocessor = WhisperProcessor.from_pretrained(\n    \"openai/whisper-tiny\", language=\"english\", task=\"transcribe\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:20.462606Z","iopub.execute_input":"2024-08-15T11:32:20.462894Z","iopub.status.idle":"2024-08-15T11:32:26.860295Z","shell.execute_reply.started":"2024-08-15T11:32:20.462870Z","shell.execute_reply":"2024-08-15T11:32:26.859286Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4a8ecf9a2e74698b906c67ca9f1b0bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54b105d4a87d431388fab0ca4bcb00ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed8c41c308df44cd95fce45c5340c641"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d820cf50e91472986f3cf7489c59054"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4767a2b7c6d47ee8be44ca254d5e118"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b84481f6da7241ce809ae59bc1924d3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c39b1541bb694a7fa93e84a9f432cc9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30c3a4f7ce384379898bf784b57e7f9d"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset[\"train\"].features","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:26.861496Z","iopub.execute_input":"2024-08-15T11:32:26.862000Z","iopub.status.idle":"2024-08-15T11:32:26.868361Z","shell.execute_reply.started":"2024-08-15T11:32:26.861973Z","shell.execute_reply":"2024-08-15T11:32:26.867505Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'audio': Audio(sampling_rate=8000, mono=True, decode=True, id=None),\n 'transcription': Value(dtype='string', id=None)}"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Audio\n\nsampling_rate = processor.feature_extractor.sampling_rate\ndataset = dataset.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))\ndataset[\"train\"].features","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:26.869671Z","iopub.execute_input":"2024-08-15T11:32:26.869970Z","iopub.status.idle":"2024-08-15T11:32:26.887049Z","shell.execute_reply.started":"2024-08-15T11:32:26.869946Z","shell.execute_reply":"2024-08-15T11:32:26.886198Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'audio': Audio(sampling_rate=16000, mono=True, decode=True, id=None),\n 'transcription': Value(dtype='string', id=None)}"},"metadata":{}}]},{"cell_type":"code","source":"def prepare_dataset(example):\n    audio = example[\"audio\"]\n\n    example = processor(\n        audio=audio[\"array\"],\n        sampling_rate=audio[\"sampling_rate\"],\n        text=example[\"transcription\"],\n    )\n    \n    example[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:26.888618Z","iopub.execute_input":"2024-08-15T11:32:26.889038Z","iopub.status.idle":"2024-08-15T11:32:26.897307Z","shell.execute_reply.started":"2024-08-15T11:32:26.889005Z","shell.execute_reply":"2024-08-15T11:32:26.896578Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(\n    prepare_dataset, remove_columns=dataset.column_names[\"train\"], num_proc=1\n)\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:26.898327Z","iopub.execute_input":"2024-08-15T11:32:26.898718Z","iopub.status.idle":"2024-08-15T11:32:54.814871Z","shell.execute_reply.started":"2024-08-15T11:32:26.898669Z","shell.execute_reply":"2024-08-15T11:32:54.813935Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/450 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3cadd22c0d1407c97e4970a5bb6aa8b"}},"metadata":{}},{"name":"stderr","text":"2024-08-15 11:32:31.044284: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-15 11:32:31.044386: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-15 11:32:31.164483: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab2987b70eba45e8b27eccf5c855fd7c"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_features', 'labels', 'input_length'],\n        num_rows: 450\n    })\n    test: Dataset({\n        features: ['input_features', 'labels', 'input_length'],\n        num_rows: 113\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 30.0\n\ndef is_audio_in_length_range(length):\n    return length < max_input_length\n\ndataset[\"train\"] = dataset[\"train\"].filter(\n    is_audio_in_length_range,\n    input_columns=[\"input_length\"],\n)\n\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:54.819089Z","iopub.execute_input":"2024-08-15T11:32:54.819817Z","iopub.status.idle":"2024-08-15T11:32:54.852265Z","shell.execute_reply.started":"2024-08-15T11:32:54.819789Z","shell.execute_reply":"2024-08-15T11:32:54.851426Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/450 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd7fb231e26b43c6912b21ac7c5415c7"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_features', 'labels', 'input_length'],\n        num_rows: 447\n    })\n    test: Dataset({\n        features: ['input_features', 'labels', 'input_length'],\n        num_rows: 113\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\n\n@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n    \n    def __call__(\n        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]\n    ) -> Dict[str, torch.Tensor]:\n        input_features = [\n            {\"input_features\": feature[\"input_features\"][0]} for feature in features\n        ]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n        labels = labels_batch[\"input_ids\"].masked_fill(\n            labels_batch.attention_mask.ne(1), -100\n        )\n        \n        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n        \n        batch[\"labels\"] = labels\n        \n        return batch","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:54.853410Z","iopub.execute_input":"2024-08-15T11:32:54.853681Z","iopub.status.idle":"2024-08-15T11:32:55.200921Z","shell.execute_reply.started":"2024-08-15T11:32:54.853658Z","shell.execute_reply":"2024-08-15T11:32:55.199932Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:55.202077Z","iopub.execute_input":"2024-08-15T11:32:55.202364Z","iopub.status.idle":"2024-08-15T11:32:55.214053Z","shell.execute_reply.started":"2024-08-15T11:32:55.202340Z","shell.execute_reply":"2024-08-15T11:32:55.213241Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"!pip install -q evaluate jiwer","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:32:55.214981Z","iopub.execute_input":"2024-08-15T11:32:55.215228Z","iopub.status.idle":"2024-08-15T11:33:10.633689Z","shell.execute_reply.started":"2024-08-15T11:32:55.215206Z","shell.execute_reply":"2024-08-15T11:33:10.632725Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\nfrom transformers.models.whisper.english_normalizer import BasicTextNormalizer\n\n\nmetric = evaluate.load(\"wer\")\nnormalizer = BasicTextNormalizer()\n\ndef compute_metrics(pred):\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n    \n    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n    \n    wer_ortho = metric.compute(predictions=pred_str, references=label_str)\n    \n    pred_str_norm = [normalizer(pred) for pred in pred_str]\n    label_str_norm = [normalizer(label) for label in label_str]\n    \n    pred_str_norm = [\n        pred_str_norm[i] for i in range(len(pred_str_norm)) if len(label_str_norm[i]) > 0\n    ]\n    label_str_norm = [\n        label_str_norm[i]\n        for i in range(len(label_str_norm))\n        if len(label_str_norm[i]) > 0\n    ]\n    \n    wer = metric.compute(predictions=pred_str_norm, references=label_str_norm)\n\n    return {\"wer_ortho\": wer_ortho, \"wer\": wer}","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:33:10.635330Z","iopub.execute_input":"2024-08-15T11:33:10.635730Z","iopub.status.idle":"2024-08-15T11:33:11.571448Z","shell.execute_reply.started":"2024-08-15T11:33:10.635681Z","shell.execute_reply":"2024-08-15T11:33:11.570462Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d484896ff0a46e1bf3d6c1295db6ef8"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import WhisperForConditionalGeneration\n\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:33:11.572404Z","iopub.execute_input":"2024-08-15T11:33:11.572683Z","iopub.status.idle":"2024-08-15T11:33:14.318087Z","shell.execute_reply.started":"2024-08-15T11:33:11.572658Z","shell.execute_reply":"2024-08-15T11:33:14.317020Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14d8a72ef2df48c1abe2541e7d69f8ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/151M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d345bd71c582460c81600f57b91772a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/3.75k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14b67a8e365e4e8dbfefafe72565c384"}},"metadata":{}}]},{"cell_type":"code","source":"from functools import partial\n\n# gradyan kontrol noktasÄ± ile uyumsuz olduÄŸu iÃ§in eÄŸitim sÄ±rasÄ±nda Ã¶nbelleÄŸi devre dÄ±ÅŸÄ± bÄ±rakÄ±n\nmodel.config.use_cache = False\n\n# Ã¼retim iÃ§in dili ve gÃ¶revi ayarlayÄ±n ve Ã¶nbelleÄŸi yeniden etkinleÅŸtirin\nmodel.generate = partial(\n    model.generate, language=\"english\", task=\"transcribe\", use_cache=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:33:14.319260Z","iopub.execute_input":"2024-08-15T11:33:14.319519Z","iopub.status.idle":"2024-08-15T11:33:14.324331Z","shell.execute_reply.started":"2024-08-15T11:33:14.319496Z","shell.execute_reply":"2024-08-15T11:33:14.323440Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./whisper-tiny-en\",\n    per_device_train_batch_size=8,\n    gradient_accumulation_steps=4,\n    learning_rate=1e-5,\n    lr_scheduler_type=\"constant_with_warmup\",\n    warmup_steps=50,\n    max_steps=200,\n    gradient_checkpointing=True,\n    fp16=True,\n    fp16_full_eval=True,\n    evaluation_strategy=\"steps\",\n    per_device_eval_batch_size=8,\n    predict_with_generate=True,\n    generation_max_length=225,\n    save_steps=100,\n    eval_steps=100,\n    logging_steps=50,\n    report_to=[\"tensorboard\"],\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:33:14.325535Z","iopub.execute_input":"2024-08-15T11:33:14.325828Z","iopub.status.idle":"2024-08-15T11:33:14.418229Z","shell.execute_reply.started":"2024-08-15T11:33:14.325805Z","shell.execute_reply":"2024-08-15T11:33:14.417266Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:33:14.419332Z","iopub.execute_input":"2024-08-15T11:33:14.419606Z","iopub.status.idle":"2024-08-15T11:33:14.444355Z","shell.execute_reply.started":"2024-08-15T11:33:14.419584Z","shell.execute_reply":"2024-08-15T11:33:14.443500Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0a246412a7c43b4a300b919120e0923"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=processor,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:35:17.705588Z","iopub.execute_input":"2024-08-15T11:35:17.706190Z","iopub.status.idle":"2024-08-15T11:35:18.695821Z","shell.execute_reply.started":"2024-08-15T11:35:17.706144Z","shell.execute_reply":"2024-08-15T11:35:18.694914Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:35:20.299589Z","iopub.execute_input":"2024-08-15T11:35:20.299967Z","iopub.status.idle":"2024-08-15T11:59:44.721482Z","shell.execute_reply.started":"2024-08-15T11:35:20.299936Z","shell.execute_reply":"2024-08-15T11:59:44.720472Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 24:07, Epoch 14/15]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Wer Ortho</th>\n      <th>Wer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.241900</td>\n      <td>0.486529</td>\n      <td>0.294230</td>\n      <td>0.286589</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.004800</td>\n      <td>0.594461</td>\n      <td>0.289791</td>\n      <td>0.289039</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\nThere were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=0.6235875126719475, metrics={'train_runtime': 1457.0057, 'train_samples_per_second': 4.393, 'train_steps_per_second': 0.137, 'total_flos': 1.5721620037632e+17, 'train_loss': 0.6235875126719475, 'epoch': 14.285714285714286})"},"metadata":{}}]},{"cell_type":"code","source":"kwargs = {\n     \"dataset_tags\": \"PolyAI/minds14\",\n    \"finetuned_from\": \"openai/whisper-tiny\",\n    \"tasks\": \"automatic-speech-recognition\",\n}\n\ntrainer.push_to_hub(**kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T11:59:44.723326Z","iopub.execute_input":"2024-08-15T11:59:44.724002Z","iopub.status.idle":"2024-08-15T11:59:47.994326Z","shell.execute_reply.started":"2024-08-15T11:59:44.723966Z","shell.execute_reply":"2024-08-15T11:59:47.993377Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Leotrim/whisper-tiny-en/commit/fb8c546f0b68c6f9adb3d70a5beba825171d3a7b', commit_message='End of training', commit_description='', oid='fb8c546f0b68c6f9adb3d70a5beba825171d3a7b', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}