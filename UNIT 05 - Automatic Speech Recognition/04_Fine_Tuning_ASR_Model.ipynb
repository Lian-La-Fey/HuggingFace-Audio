{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine-tuning the ASR model\n\nBu bölümde, Common Voice 13 veri kümesinde konuşma tanıma için Whisper'a ince ayar yapma konusunda adım adım bir kılavuz ele alacağız. Modelin 'küçük' sürümünü ve nispeten hafif bir veri kümesini kullanacağız, bu da Google Colab ücretsiz katmanında sağlanan 16GB T4 GPU gibi düşük disk alanı gereksinimleri olan herhangi bir 16GB + GPU'da oldukça hızlı bir şekilde ince ayar yapmanızı sağlar.\n\nDaha küçük bir GPU'ya sahipseniz veya eğitim sırasında bellek sorunlarıyla karşılaşırsanız, bellek kullanımını azaltmak için verilen önerileri uygulayabilirsiniz. Tersine, daha büyük bir GPU'ya erişiminiz varsa, veriminizi en üst düzeye çıkarmak için eğitim argümanlarını değiştirebilirsiniz. Dolayısıyla, bu kılavuz GPU özelliklerinizden bağımsız olarak erişilebilirdir!\n\nAynı şekilde, bu kılavuz Dhivehi dili için Whisper modeline nasıl ince ayar yapılacağını özetlemektedir. Ancak burada anlatılan adımlar, Ortak Ses veri kümesindeki herhangi bir dile ve daha genel olarak Hugging Face Hub'daki herhangi bir ASR veri kümesine genelleştirilebilir. İstediğiniz bir dile hızlıca geçmek ve ana dilinizde bir Fısıltı modeline ince ayar yapmak için kodu değiştirebilirsiniz 🌍\n\nTamam! Şimdi bunu aradan çıkardığımıza göre, başlayalım ve ince ayar hattımızı başlatalım!","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:54:53.547966Z","iopub.execute_input":"2024-08-15T04:54:53.548785Z","iopub.status.idle":"2024-08-15T04:54:53.846987Z","shell.execute_reply.started":"2024-08-15T04:54:53.548741Z","shell.execute_reply":"2024-08-15T04:54:53.846045Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c45f2f3907d048e1bb89234eab4a2491"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict\n\ncommon_voice = DatasetDict()\ncommon_voice[\"train\"] = load_dataset(\n    \"mozilla-foundation/common_voice_13_0\", \"dv\", split=\"train+validation\",\n    trust_remote_code=True\n)\n\ncommon_voice[\"test\"] = load_dataset(\n    \"mozilla-foundation/common_voice_13_0\", \"dv\", split=\"test\",\n    trust_remote_code=True\n)\n\ncommon_voice","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:55:11.166996Z","iopub.execute_input":"2024-08-15T04:55:11.168020Z","iopub.status.idle":"2024-08-15T04:55:56.946602Z","shell.execute_reply.started":"2024-08-15T04:55:11.167979Z","shell.execute_reply":"2024-08-15T04:55:56.945580Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b2c5f6aaf434fc6b75793811153e2e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/14.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdcadfabf3ce4dba856a0a815f9a5266"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0c2550038614e039288816bf5eba1d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/65.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa8c1258e34441a8bcdcfbd6ce2f1c84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35ed8c1a5345463e82e0be9e1d934186"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/96.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f671e716c6284458a16cb21545ffc98c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/88.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5fba5427446478d8985c1382c8f83e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/89.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a4a6c9e006346399591654ddfea4696"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/477M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a765080f0b774e80aa8d1cd9ca91cac9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/64.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ce7ebcd16d2420480d91c0586c35e3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/787k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e20029166ea34e779c3702f7f3c5e9c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/650k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f990be726f9d4738a1ef828a3bda3a59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/636k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee532d2b0f034f91aa2aef4fdca3f49b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d326a1e07755481abaa7f6d8ba6c3db2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/501k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14a2cefce0154fae8a00a2bcec4d2fc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a99e8455263f43aa9cada9cf0944bdbe"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 2677it [00:00, 73917.08it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"167c4b0729b34a7bb392ae619956f03d"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 0it [00:00, ?it/s]\u001b[A\nReading metadata...: 2227it [00:00, 20927.03it/s]\u001b[A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"077bf32aa9bb47d1a3f44acbae8ce9f2"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 2212it [00:00, 76485.14it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating other split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab2ddf9300974cd9a62b694a4b4f46b7"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 0it [00:00, ?it/s]\u001b[A\nReading metadata...: 16395it [00:00, 98800.74it/s][A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating invalidated split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acc3be831abe48179c784438b4ac657c"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 1653it [00:00, 75315.68it/s]\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n        num_rows: 4904\n    })\n    test: Dataset({\n        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n        num_rows: 2212\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"common_voice = common_voice.select_columns([\"audio\", \"sentence\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:55:56.948137Z","iopub.execute_input":"2024-08-15T04:55:56.948449Z","iopub.status.idle":"2024-08-15T04:55:56.957799Z","shell.execute_reply.started":"2024-08-15T04:55:56.948423Z","shell.execute_reply":"2024-08-15T04:55:56.957062Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extractor, Tokenizer and Processor\n\nASR pipeline üç aşamaya ayrılabilir:\n\n- Ham ses girişlerini log-mel spektrogramlarına ön işleme tabi tutan özellik çıkarıcı\n- Diziden diziye eşlemeyi gerçekleştiren model\n- Tahmin edilen tokenleri sonradan işleyerek metne dönüştüren tokenizer\n\nTransformers'da, Whisper modelinin sırasıyla WhisperFeatureExtractor ve WhisperTokenizer olarak adlandırılan ilişkili bir özellik çıkarıcısı ve belirteci vardır. Hayatımızı kolaylaştırmak için, bu iki nesne WhisperProcessor adı verilen tek bir sınıf altında toplanmıştır. Hem ses ön işleme hem de metin belirteci son işleme işlemlerini gerçekleştirmek için WhisperProcessor'ı çağırabiliriz. Bunu yaparken, eğitim sırasında yalnızca iki nesneyi takip etmemiz gerekir: işleyici ve model.\n\nÇok dilli ince ayar yaparken, işlemciyi örneklendirirken \"dil\" ve \"görev\" ayarlarını yapmamız gerekir. \"Dil\" kaynak ses diline, görev ise konuşma tanıma için \"transcribe\" veya konuşma çevirisi için \"translate\" olarak ayarlanmalıdır. Bu argümanlar tokenizer'ın davranışını değiştirir ve hedef etiketlerin düzgün kodlandığından emin olmak için doğru şekilde ayarlanmalıdır.\n\nDil listesini içe aktararak Whisper tarafından desteklenen tüm olası dilleri görebiliriz:","metadata":{}},{"cell_type":"code","source":"from transformers.models.whisper.tokenization_whisper import TO_LANGUAGE_CODE\n\nTO_LANGUAGE_CODE","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:55:56.958809Z","iopub.execute_input":"2024-08-15T04:55:56.959073Z","iopub.status.idle":"2024-08-15T04:56:05.443976Z","shell.execute_reply.started":"2024-08-15T04:55:56.959049Z","shell.execute_reply":"2024-08-15T04:56:05.443089Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'english': 'en',\n 'chinese': 'zh',\n 'german': 'de',\n 'spanish': 'es',\n 'russian': 'ru',\n 'korean': 'ko',\n 'french': 'fr',\n 'japanese': 'ja',\n 'portuguese': 'pt',\n 'turkish': 'tr',\n 'polish': 'pl',\n 'catalan': 'ca',\n 'dutch': 'nl',\n 'arabic': 'ar',\n 'swedish': 'sv',\n 'italian': 'it',\n 'indonesian': 'id',\n 'hindi': 'hi',\n 'finnish': 'fi',\n 'vietnamese': 'vi',\n 'hebrew': 'he',\n 'ukrainian': 'uk',\n 'greek': 'el',\n 'malay': 'ms',\n 'czech': 'cs',\n 'romanian': 'ro',\n 'danish': 'da',\n 'hungarian': 'hu',\n 'tamil': 'ta',\n 'norwegian': 'no',\n 'thai': 'th',\n 'urdu': 'ur',\n 'croatian': 'hr',\n 'bulgarian': 'bg',\n 'lithuanian': 'lt',\n 'latin': 'la',\n 'maori': 'mi',\n 'malayalam': 'ml',\n 'welsh': 'cy',\n 'slovak': 'sk',\n 'telugu': 'te',\n 'persian': 'fa',\n 'latvian': 'lv',\n 'bengali': 'bn',\n 'serbian': 'sr',\n 'azerbaijani': 'az',\n 'slovenian': 'sl',\n 'kannada': 'kn',\n 'estonian': 'et',\n 'macedonian': 'mk',\n 'breton': 'br',\n 'basque': 'eu',\n 'icelandic': 'is',\n 'armenian': 'hy',\n 'nepali': 'ne',\n 'mongolian': 'mn',\n 'bosnian': 'bs',\n 'kazakh': 'kk',\n 'albanian': 'sq',\n 'swahili': 'sw',\n 'galician': 'gl',\n 'marathi': 'mr',\n 'punjabi': 'pa',\n 'sinhala': 'si',\n 'khmer': 'km',\n 'shona': 'sn',\n 'yoruba': 'yo',\n 'somali': 'so',\n 'afrikaans': 'af',\n 'occitan': 'oc',\n 'georgian': 'ka',\n 'belarusian': 'be',\n 'tajik': 'tg',\n 'sindhi': 'sd',\n 'gujarati': 'gu',\n 'amharic': 'am',\n 'yiddish': 'yi',\n 'lao': 'lo',\n 'uzbek': 'uz',\n 'faroese': 'fo',\n 'haitian creole': 'ht',\n 'pashto': 'ps',\n 'turkmen': 'tk',\n 'nynorsk': 'nn',\n 'maltese': 'mt',\n 'sanskrit': 'sa',\n 'luxembourgish': 'lb',\n 'myanmar': 'my',\n 'tibetan': 'bo',\n 'tagalog': 'tl',\n 'malagasy': 'mg',\n 'assamese': 'as',\n 'tatar': 'tt',\n 'hawaiian': 'haw',\n 'lingala': 'ln',\n 'hausa': 'ha',\n 'bashkir': 'ba',\n 'javanese': 'jw',\n 'sundanese': 'su',\n 'cantonese': 'yue',\n 'burmese': 'my',\n 'valencian': 'ca',\n 'flemish': 'nl',\n 'haitian': 'ht',\n 'letzeburgesch': 'lb',\n 'pushto': 'ps',\n 'panjabi': 'pa',\n 'moldavian': 'ro',\n 'moldovan': 'ro',\n 'sinhalese': 'si',\n 'castilian': 'es',\n 'mandarin': 'zh'}"},"metadata":{}}]},{"cell_type":"markdown","source":"Bu listede gezinirseniz, birçok dilin mevcut olduğunu, ancak Dhivehi'nin mevcut olmayan birkaç dilden biri olduğunu fark edeceksiniz! Bu, Whisper'ın Dhivehi üzerinde önceden eğitilmediği anlamına gelir. Ancak bu, Whisper üzerinde ince ayar yapamayacağımız anlamına gelmez. Bunu yaparken, Whisper'a önceden eğitilmiş kontrol noktasının desteklemediği yeni bir dil öğreteceğiz. Bu oldukça havalı, değil mi!\n\nYeni bir dilde ince ayar yaptığınızda, Whisper önceden eğitildiği diğer 96 dil hakkındaki bilgisinden yararlanma konusunda iyi bir iş çıkarır. Büyük ölçüde konuşursak, tüm modern diller Whisper'ın zaten bildiği 96 dilden en az birine dilsel olarak benzer olacaktır, bu nedenle bu diller arası bilgi temsili paradigmasına gireceğiz.\n\nWhisper'a yeni bir dilde ince ayar yapmak için yapmamız gereken şey, Whisper'ın önceden eğitildiği en benzer dili bulmaktır. Dhivehi için Wikipedia makalesinde Dhivehi'nin Sri Lanka'nın Sinhalese dili ile yakından ilişkili olduğu belirtilmektedir. Dil kodlarını tekrar kontrol edersek, Sinhalese dilinin Whisper dil setinde mevcut olduğunu görebiliriz, bu nedenle dil argümanımızı güvenle \"sinhalese\" olarak ayarlayabiliriz.\n\nTamamdır! İşlemcimizi önceden eğitilmiş kontrol noktasından yükleyeceğiz, dili \"sinhalese\" olarak ve görevi yukarıda açıklandığı gibi \"transcribe\" olarak ayarlayacağız:","metadata":{}},{"cell_type":"code","source":"from transformers import WhisperProcessor\n\nprocessor = WhisperProcessor.from_pretrained(\n    \"openai/whisper-small\", language=\"sinhalese\", task=\"transcribe\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:56:05.446673Z","iopub.execute_input":"2024-08-15T04:56:05.447270Z","iopub.status.idle":"2024-08-15T04:56:10.105792Z","shell.execute_reply.started":"2024-08-15T04:56:05.447243Z","shell.execute_reply":"2024-08-15T04:56:10.104773Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bda26cabedb4c2ba3378913f5e30f79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b380949c6764852b046ef3ad984fc82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dda7d8f114654d7886f6a33579d91b44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2b379b16cfa481ba2044968476eb690"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c9332516b7945ab839b6320cf1de9d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d71aee44fee420398fa66a53cb0240f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afc4cb6432714769a25240ff2cc6cc73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"806d0b8209ba478f95f28ee90d39e6ae"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Çoğu durumda, ince ayar yapmak istediğiniz dilin ön eğitim dilleri kümesinde olduğunu göreceksiniz, bu durumda dili doğrudan kaynak ses diliniz olarak ayarlayabilirsiniz! Dil (\"English\") ve görev (\"transcribe\") için yalnızca bir seçeneğin bulunduğu yalnızca İngilizce ince ayar için bu iki argümanın da atlanması gerektiğini unutmayın.","metadata":{}},{"cell_type":"markdown","source":"## Pre-Process the Data\n\nVeri kümesi özelliklerine bir göz atalım. \"Ses\" sütununa özellikle dikkat edin - bu, ses girişlerimizin örnekleme oranını detaylandırır:","metadata":{}},{"cell_type":"code","source":"common_voice[\"train\"].features","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:56:10.107042Z","iopub.execute_input":"2024-08-15T04:56:10.107560Z","iopub.status.idle":"2024-08-15T04:56:10.113644Z","shell.execute_reply.started":"2024-08-15T04:56:10.107531Z","shell.execute_reply":"2024-08-15T04:56:10.112785Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'audio': Audio(sampling_rate=48000, mono=True, decode=True, id=None),\n 'sentence': Value(dtype='string', id=None)}"},"metadata":{}}]},{"cell_type":"markdown","source":"Giriş sesimiz 48kHz'de örneklendiğinden, Whisper özellik çıkarıcısına aktarmadan önce 16kHz'ye düşürmemiz gerekir; 16kHz, Whisper modeli tarafından beklenen örnekleme hızıdır.\n\nDataset'in cast_column yöntemini kullanarak ses girişlerini doğru örnekleme hızına ayarlayacağız. Bu işlem sesi yerinde değiştirmez, bunun yerine veri kümelerine yüklendiklerinde ses örneklerini anında yeniden örneklemeleri için sinyal verir:","metadata":{}},{"cell_type":"code","source":"from datasets import Audio\n\nsampling_rate = processor.feature_extractor.sampling_rate\ncommon_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:56:10.114743Z","iopub.execute_input":"2024-08-15T04:56:10.115038Z","iopub.status.idle":"2024-08-15T04:56:10.131685Z","shell.execute_reply.started":"2024-08-15T04:56:10.115010Z","shell.execute_reply":"2024-08-15T04:56:10.130831Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Şimdi verilerimizi modele hazır hale getirmek için bir fonksiyon yazabiliriz:\n\n- sample[\"audio\"] çağrısı yaparak ses verilerini örnek bazında yükler ve yeniden örneklendiririz. Yukarıda açıklandığı gibi, Datasets gerekli yeniden örnekleme işlemlerini anında gerçekleştirir.\n- Log-mel spektrogram giriş özelliklerini 1 boyutlu ses dizimizden hesaplamak için özellik çıkarıcıyı kullanıyoruz.\n- Transkripsiyonları tokenizer kullanarak etiket kimliklerine kodluyoruz.","metadata":{}},{"cell_type":"code","source":"def prepare_dataset(example):\n    audio = example[\"audio\"]\n\n    example = processor(\n        audio=audio[\"array\"],\n        sampling_rate=audio[\"sampling_rate\"],\n        text=example[\"sentence\"],\n    )\n    \n    example[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:56:10.132957Z","iopub.execute_input":"2024-08-15T04:56:10.133761Z","iopub.status.idle":"2024-08-15T04:56:10.141066Z","shell.execute_reply.started":"2024-08-15T04:56:10.133725Z","shell.execute_reply":"2024-08-15T04:56:10.140216Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"common_voice = common_voice.map(\n    prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=1\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:56:10.142187Z","iopub.execute_input":"2024-08-15T04:56:10.142473Z","iopub.status.idle":"2024-08-15T04:59:10.147169Z","shell.execute_reply.started":"2024-08-15T04:56:10.142449Z","shell.execute_reply":"2024-08-15T04:59:10.146258Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4904 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88d3ea6665764bc5a8686f2729a43933"}},"metadata":{}},{"name":"stderr","text":"2024-08-15 04:56:27.137746: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-15 04:56:27.138068: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-15 04:56:27.306280: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2212 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a17b7ad2cc14529aa63fedf72ffaf5a"}},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 30.0\n\ndef is_audio_in_length_range(length):\n    return length < max_input_length\n\ncommon_voice[\"train\"] = common_voice[\"train\"].filter(\n    is_audio_in_length_range,\n    input_columns=[\"input_length\"],\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:10.148288Z","iopub.execute_input":"2024-08-15T04:59:10.148953Z","iopub.status.idle":"2024-08-15T04:59:10.186986Z","shell.execute_reply.started":"2024-08-15T04:59:10.148925Z","shell.execute_reply":"2024-08-15T04:59:10.186142Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/4904 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7e71a9fba2340819fe2ac9ba8b1537e"}},"metadata":{}}]},{"cell_type":"code","source":"common_voice[\"train\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:10.189914Z","iopub.execute_input":"2024-08-15T04:59:10.190188Z","iopub.status.idle":"2024-08-15T04:59:14.284122Z","shell.execute_reply.started":"2024-08-15T04:59:10.190163Z","shell.execute_reply":"2024-08-15T04:59:14.283224Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_features', 'labels', 'input_length'],\n    num_rows: 4904\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"Bu durumda aslında daha önce olduğu gibi aynı sayıda örneğe sahibiz, yani 30 saniyeden uzun örnek yok. Dil değiştirdiğinizde durum böyle olmayabilir, bu nedenle sağlamlık için bu filtre adımını yerinde tutmak en iyisidir. Bununla birlikte, verilerimiz eğitim için tamamen hazır! Devam edelim ve Whisper'a ince ayar yapmak için bu verileri nasıl kullanabileceğimize bir göz atalım.","metadata":{}},{"cell_type":"markdown","source":"## Training and Evaluation\n\nVerilerimizi hazırladığımıza göre artık eğitim hattına dalmaya hazırız. Trainer bizim için ağır işlerin çoğunu yapacaktır. Tek yapmamız gereken\n\n- Bir veri harmanlayıcı tanımlamak: veri harmanlayıcı önceden işlenmiş verilerimizi alır ve PyTorch tensörlerini model için hazırlar.\n\n- Değerlendirme metrikleri: Değerlendirme sırasında, modeli kelime hata oranı (WER) metriğini kullanarak değerlendirmek istiyoruz. Bu hesaplamayı gerçekleştiren bir compute_metrics fonksiyonu tanımlamamız gerekiyor.\n\n- Önceden eğitilmiş bir kontrol noktası yükleyin: önceden eğitilmiş bir kontrol noktası yüklememiz ve eğitim için doğru şekilde yapılandırmamız gerekir.\n\n- Eğitim argümanlarını tanımlayın: bunlar Trainer tarafından eğitim programını oluştururken kullanılacaktır.\n\nModele ince ayar yaptıktan sonra, Dhivehi dilinde konuşmayı yazıya dökmek üzere doğru şekilde eğittiğimizi doğrulamak için test verileri üzerinde değerlendireceğiz.","metadata":{}},{"cell_type":"markdown","source":"### Define a Data Collator\n\nBir diziden diziye konuşma modeli için veri harmanlayıcı, input_features ve label'ları bağımsız olarak ele alması bakımından benzersizdir: input_features feature extractor tarafından, label'lar ise tokenizer tarafından ele alınmalıdır.\n\nInput_features zaten 30'lara dolgulanmış ve sabit boyutlu bir log-Mel spektrogramına dönüştürülmüştür, bu nedenle tek yapmamız gereken onları toplu PyTorch tensörlerine dönüştürmektir. Bunu return_tensors=pt ile özellik çıkarıcının .pad yöntemini kullanarak yapıyoruz. Girdiler sabit boyutlu olduğu için burada ek bir dolgu uygulanmadığına dikkat edin, input_features basitçe PyTorch tensörlerine dönüştürülür.\n\nÖte yandan, etiketler dolgusuzdur. İlk olarak tokenizer'ın .pad yöntemini kullanarak dizileri yığındaki maksimum uzunluğa kadar dolduruyoruz. Dolgu belirteçleri daha sonra -100 ile değiştirilir, böylece kayıp hesaplanırken bu belirteçler dikkate alınmaz. Daha sonra eğitim sırasında eklediğimiz transkript belirtecinin başlangıcını etiket dizisinin başından kesiyoruz.\n\nHem özellik çıkarıcı hem de tokenizer işlemlerini gerçekleştirmek için daha önce tanımladığımız WhisperProcessor'dan faydalanabiliriz:","metadata":{}},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\n\n@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n    \n    def __call__(\n        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]\n    ) -> Dict[str, torch.Tensor]:\n        input_features = [\n            {\"input_features\": feature[\"input_features\"][0]} for feature in features\n        ]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n        labels = labels_batch[\"input_ids\"].masked_fill(\n            labels_batch.attention_mask.ne(1), -100\n        )\n        \n        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n        \n        batch[\"labels\"] = labels\n        \n        return batch","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:14.285387Z","iopub.execute_input":"2024-08-15T04:59:14.285660Z","iopub.status.idle":"2024-08-15T04:59:14.296282Z","shell.execute_reply.started":"2024-08-15T04:59:14.285636Z","shell.execute_reply":"2024-08-15T04:59:14.295564Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:14.297344Z","iopub.execute_input":"2024-08-15T04:59:14.297647Z","iopub.status.idle":"2024-08-15T04:59:14.312233Z","shell.execute_reply.started":"2024-08-15T04:59:14.297622Z","shell.execute_reply":"2024-08-15T04:59:14.311365Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation Metrics\n\nArdından, değerlendirme setimizde kullanacağımız değerlendirme metriğini tanımlıyoruz. ASR sistemlerini değerlendirmek için 'de-facto' metrik olan Değerlendirme bölümünde tanıtılan Kelime Hata Oranı (WER) metriğini kullanacağız.","metadata":{}},{"cell_type":"code","source":"!pip install -q evaluate jiwer","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:14.313367Z","iopub.execute_input":"2024-08-15T04:59:14.313788Z","iopub.status.idle":"2024-08-15T04:59:29.907333Z","shell.execute_reply.started":"2024-08-15T04:59:14.313755Z","shell.execute_reply":"2024-08-15T04:59:29.906343Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Daha sonra model tahminlerimizi alan ve WER metriğini döndüren bir fonksiyon tanımlamamız yeterlidir. compute_metrics adı verilen bu fonksiyon, ilk olarak label_ids'deki pad_token_id ile -100'ü değiştirir (kayıpta dolgulu belirteçleri doğru şekilde yok saymak için veri harmanlayıcıda uyguladığımız adımı geri alır). Daha sonra tahmin edilen ve etiket kimliklerini dizelere çözer. Son olarak, tahminler ve referans etiketleri arasındaki WER değerini hesaplar. Burada, noktalama işaretleri ve büyük/küçük harfler kaldırılmış 'normalleştirilmiş' transkripsiyonlar ve tahminlerle değerlendirme seçeneğimiz vardır. Transkripsiyonları normalleştirerek elde edilen WER iyileştirmesinden yararlanmak için bunu izlemenizi öneririz.","metadata":{}},{"cell_type":"code","source":"import evaluate\nfrom transformers.models.whisper.english_normalizer import BasicTextNormalizer\n\n\nmetric = evaluate.load(\"wer\")\nnormalizer = BasicTextNormalizer()\n\ndef compute_metrics(pred):\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n    \n    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n    \n    wer_ortho = 100 * metric.compute(predictions=pred_str, references=label_str)\n    \n    pred_str_norm = [normalizer(pred) for pred in pred_str]\n    label_str_norm = [normalizer(label) for label in label_str]\n    \n    pred_str_norm = [\n        pred_str_norm[i] for i in range(len(pred_str_norm)) if len(label_str_norm[i]) > 0\n    ]\n    label_str_norm = [\n        label_str_norm[i]\n        for i in range(len(label_str_norm))\n        if len(label_str_norm[i]) > 0\n    ]\n    \n    wer = 100 * metric.compute(predictions=pred_str_norm, references=label_str_norm)\n\n    return {\"wer_ortho\": wer_ortho, \"wer\": wer}","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:29.909047Z","iopub.execute_input":"2024-08-15T04:59:29.909435Z","iopub.status.idle":"2024-08-15T04:59:30.966775Z","shell.execute_reply.started":"2024-08-15T04:59:29.909405Z","shell.execute_reply":"2024-08-15T04:59:30.965886Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cc8b7d711174baaa833ea15e266eae3"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import WhisperForConditionalGeneration\n\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:30.967916Z","iopub.execute_input":"2024-08-15T04:59:30.968175Z","iopub.status.idle":"2024-08-15T04:59:35.549834Z","shell.execute_reply.started":"2024-08-15T04:59:30.968152Z","shell.execute_reply":"2024-08-15T04:59:35.549068Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d92eb3e7f23f4ccb89570ce10c1b1d5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bd05d40b97a4fe0a25c824c58fd2e44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/3.87k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fddf6017cf440f0885259050f9a722d"}},"metadata":{}}]},{"cell_type":"markdown","source":"Gradyan kontrol noktası kullandığımız ve ikisi uyumsuz olduğu için `use_cache`'i eğitim için **False** olarak ayarlayacağız. Ayrıca çıkarım sırasında modelin davranışını kontrol etmek için iki üretim argümanını geçersiz kılacağız: dil ve görev argümanlarını ayarlayarak üretim sırasında dil ve görev belirteçlerini zorlayacağız ve ayrıca çıkarım süresini hızlandırmak için üretim için önbelleği yeniden etkinleştireceğiz:","metadata":{}},{"cell_type":"code","source":"from functools import partial\n\n# gradyan kontrol noktası ile uyumsuz olduğu için eğitim sırasında önbelleği devre dışı bırakın\nmodel.config.use_cache = False\n\n# üretim için dili ve görevi ayarlayın ve önbelleği yeniden etkinleştirin\nmodel.generate = partial(\n    model.generate, language=\"sinhalese\", task=\"transcribe\", use_cache=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:35.551033Z","iopub.execute_input":"2024-08-15T04:59:35.551327Z","iopub.status.idle":"2024-08-15T04:59:35.556366Z","shell.execute_reply.started":"2024-08-15T04:59:35.551286Z","shell.execute_reply":"2024-08-15T04:59:35.555429Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./whisper-small-dv\",\n    per_device_train_batch_size=8,\n    gradient_accumulation_steps=4,\n    learning_rate=1e-5,\n    lr_scheduler_type=\"constant_with_warmup\",\n    warmup_steps=50,\n    max_steps=500,\n    gradient_checkpointing=True,\n    fp16=True,\n    fp16_full_eval=True,\n    evaluation_strategy=\"steps\",\n    per_device_eval_batch_size=8,\n    predict_with_generate=True,\n    generation_max_length=225,\n    save_steps=250,\n    eval_steps=250,\n    logging_steps=50,\n    report_to=[\"tensorboard\"],\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:35.557564Z","iopub.execute_input":"2024-08-15T04:59:35.557829Z","iopub.status.idle":"2024-08-15T04:59:35.964449Z","shell.execute_reply.started":"2024-08-15T04:59:35.557807Z","shell.execute_reply":"2024-08-15T04:59:35.963457Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=common_voice[\"train\"],\n    eval_dataset=common_voice[\"test\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=processor,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:35.965617Z","iopub.execute_input":"2024-08-15T04:59:35.965918Z","iopub.status.idle":"2024-08-15T04:59:36.595681Z","shell.execute_reply.started":"2024-08-15T04:59:35.965892Z","shell.execute_reply":"2024-08-15T04:59:36.594786Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:36.596958Z","iopub.execute_input":"2024-08-15T04:59:36.597321Z","iopub.status.idle":"2024-08-15T08:36:13.530280Z","shell.execute_reply.started":"2024-08-15T04:59:36.597272Z","shell.execute_reply":"2024-08-15T08:36:13.529387Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [500/500 3:35:50, Epoch 3/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Wer Ortho</th>\n      <th>Wer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>250</td>\n      <td>0.185800</td>\n      <td>0.203400</td>\n      <td>69.691483</td>\n      <td>15.810064</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.074700</td>\n      <td>0.166556</td>\n      <td>60.247928</td>\n      <td>12.868171</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\nThere were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=500, training_loss=0.7941111783981323, metrics={'train_runtime': 12969.1672, 'train_samples_per_second': 1.234, 'train_steps_per_second': 0.039, 'total_flos': 4.61736640512e+18, 'train_loss': 0.7941111783981323, 'epoch': 3.262642740619902})"},"metadata":{}}]},{"cell_type":"code","source":"kwargs = {\n    \"dataset_tags\": \"mozilla-foundation/common_voice_13_0\",\n    \"dataset\": \"Common Voice 13\",\n    \"language\": \"dv\",\n    \"model_name\": \"Whisper-Small-Dv-fine-tuned\",\n    \"finetuned_from\": \"openai/whisper-small\",\n    \"tasks\": \"automatic-speech-recognition\",\n}\n\ntrainer.push_to_hub(**kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:36:13.531485Z","iopub.execute_input":"2024-08-15T08:36:13.531792Z","iopub.status.idle":"2024-08-15T08:36:21.033413Z","shell.execute_reply.started":"2024-08-15T08:36:13.531763Z","shell.execute_reply":"2024-08-15T08:36:21.032456Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Leotrim/whisper-small-dv/commit/2c156254258472e3d93d70a389f2146aaf3c86f2', commit_message='End of training', commit_description='', oid='2c156254258472e3d93d70a389f2146aaf3c86f2', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}