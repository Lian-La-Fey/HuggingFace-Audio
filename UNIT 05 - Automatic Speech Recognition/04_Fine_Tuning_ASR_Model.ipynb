{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine-tuning the ASR model\n\nBu bÃ¶lÃ¼mde, Common Voice 13 veri kÃ¼mesinde konuÅŸma tanÄ±ma iÃ§in Whisper'a ince ayar yapma konusunda adÄ±m adÄ±m bir kÄ±lavuz ele alacaÄŸÄ±z. Modelin 'kÃ¼Ã§Ã¼k' sÃ¼rÃ¼mÃ¼nÃ¼ ve nispeten hafif bir veri kÃ¼mesini kullanacaÄŸÄ±z, bu da Google Colab Ã¼cretsiz katmanÄ±nda saÄŸlanan 16GB T4 GPU gibi dÃ¼ÅŸÃ¼k disk alanÄ± gereksinimleri olan herhangi bir 16GB + GPU'da oldukÃ§a hÄ±zlÄ± bir ÅŸekilde ince ayar yapmanÄ±zÄ± saÄŸlar.\n\nDaha kÃ¼Ã§Ã¼k bir GPU'ya sahipseniz veya eÄŸitim sÄ±rasÄ±nda bellek sorunlarÄ±yla karÅŸÄ±laÅŸÄ±rsanÄ±z, bellek kullanÄ±mÄ±nÄ± azaltmak iÃ§in verilen Ã¶nerileri uygulayabilirsiniz. Tersine, daha bÃ¼yÃ¼k bir GPU'ya eriÅŸiminiz varsa, veriminizi en Ã¼st dÃ¼zeye Ã§Ä±karmak iÃ§in eÄŸitim argÃ¼manlarÄ±nÄ± deÄŸiÅŸtirebilirsiniz. DolayÄ±sÄ±yla, bu kÄ±lavuz GPU Ã¶zelliklerinizden baÄŸÄ±msÄ±z olarak eriÅŸilebilirdir!\n\nAynÄ± ÅŸekilde, bu kÄ±lavuz Dhivehi dili iÃ§in Whisper modeline nasÄ±l ince ayar yapÄ±lacaÄŸÄ±nÄ± Ã¶zetlemektedir. Ancak burada anlatÄ±lan adÄ±mlar, Ortak Ses veri kÃ¼mesindeki herhangi bir dile ve daha genel olarak Hugging Face Hub'daki herhangi bir ASR veri kÃ¼mesine genelleÅŸtirilebilir. Ä°stediÄŸiniz bir dile hÄ±zlÄ±ca geÃ§mek ve ana dilinizde bir FÄ±sÄ±ltÄ± modeline ince ayar yapmak iÃ§in kodu deÄŸiÅŸtirebilirsiniz ğŸŒ\n\nTamam! Åimdi bunu aradan Ã§Ä±kardÄ±ÄŸÄ±mÄ±za gÃ¶re, baÅŸlayalÄ±m ve ince ayar hattÄ±mÄ±zÄ± baÅŸlatalÄ±m!","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:54:53.547966Z","iopub.execute_input":"2024-08-15T04:54:53.548785Z","iopub.status.idle":"2024-08-15T04:54:53.846987Z","shell.execute_reply.started":"2024-08-15T04:54:53.548741Z","shell.execute_reply":"2024-08-15T04:54:53.846045Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c45f2f3907d048e1bb89234eab4a2491"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict\n\ncommon_voice = DatasetDict()\ncommon_voice[\"train\"] = load_dataset(\n    \"mozilla-foundation/common_voice_13_0\", \"dv\", split=\"train+validation\",\n    trust_remote_code=True\n)\n\ncommon_voice[\"test\"] = load_dataset(\n    \"mozilla-foundation/common_voice_13_0\", \"dv\", split=\"test\",\n    trust_remote_code=True\n)\n\ncommon_voice","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:55:11.166996Z","iopub.execute_input":"2024-08-15T04:55:11.168020Z","iopub.status.idle":"2024-08-15T04:55:56.946602Z","shell.execute_reply.started":"2024-08-15T04:55:11.167979Z","shell.execute_reply":"2024-08-15T04:55:56.945580Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b2c5f6aaf434fc6b75793811153e2e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/14.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdcadfabf3ce4dba856a0a815f9a5266"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0c2550038614e039288816bf5eba1d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/65.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa8c1258e34441a8bcdcfbd6ce2f1c84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35ed8c1a5345463e82e0be9e1d934186"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/96.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f671e716c6284458a16cb21545ffc98c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/88.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5fba5427446478d8985c1382c8f83e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/89.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a4a6c9e006346399591654ddfea4696"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/477M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a765080f0b774e80aa8d1cd9ca91cac9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/64.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ce7ebcd16d2420480d91c0586c35e3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/787k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e20029166ea34e779c3702f7f3c5e9c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/650k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f990be726f9d4738a1ef828a3bda3a59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/636k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee532d2b0f034f91aa2aef4fdca3f49b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d326a1e07755481abaa7f6d8ba6c3db2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/501k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14a2cefce0154fae8a00a2bcec4d2fc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a99e8455263f43aa9cada9cf0944bdbe"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 2677it [00:00, 73917.08it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"167c4b0729b34a7bb392ae619956f03d"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 0it [00:00, ?it/s]\u001b[A\nReading metadata...: 2227it [00:00, 20927.03it/s]\u001b[A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"077bf32aa9bb47d1a3f44acbae8ce9f2"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 2212it [00:00, 76485.14it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating other split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab2ddf9300974cd9a62b694a4b4f46b7"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 0it [00:00, ?it/s]\u001b[A\nReading metadata...: 16395it [00:00, 98800.74it/s][A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating invalidated split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acc3be831abe48179c784438b4ac657c"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 1653it [00:00, 75315.68it/s]\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n        num_rows: 4904\n    })\n    test: Dataset({\n        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n        num_rows: 2212\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"common_voice = common_voice.select_columns([\"audio\", \"sentence\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:55:56.948137Z","iopub.execute_input":"2024-08-15T04:55:56.948449Z","iopub.status.idle":"2024-08-15T04:55:56.957799Z","shell.execute_reply.started":"2024-08-15T04:55:56.948423Z","shell.execute_reply":"2024-08-15T04:55:56.957062Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extractor, Tokenizer and Processor\n\nASR pipeline Ã¼Ã§ aÅŸamaya ayrÄ±labilir:\n\n- Ham ses giriÅŸlerini log-mel spektrogramlarÄ±na Ã¶n iÅŸleme tabi tutan Ã¶zellik Ã§Ä±karÄ±cÄ±\n- Diziden diziye eÅŸlemeyi gerÃ§ekleÅŸtiren model\n- Tahmin edilen tokenleri sonradan iÅŸleyerek metne dÃ¶nÃ¼ÅŸtÃ¼ren tokenizer\n\nTransformers'da, Whisper modelinin sÄ±rasÄ±yla WhisperFeatureExtractor ve WhisperTokenizer olarak adlandÄ±rÄ±lan iliÅŸkili bir Ã¶zellik Ã§Ä±karÄ±cÄ±sÄ± ve belirteci vardÄ±r. HayatÄ±mÄ±zÄ± kolaylaÅŸtÄ±rmak iÃ§in, bu iki nesne WhisperProcessor adÄ± verilen tek bir sÄ±nÄ±f altÄ±nda toplanmÄ±ÅŸtÄ±r. Hem ses Ã¶n iÅŸleme hem de metin belirteci son iÅŸleme iÅŸlemlerini gerÃ§ekleÅŸtirmek iÃ§in WhisperProcessor'Ä± Ã§aÄŸÄ±rabiliriz. Bunu yaparken, eÄŸitim sÄ±rasÄ±nda yalnÄ±zca iki nesneyi takip etmemiz gerekir: iÅŸleyici ve model.\n\nÃ‡ok dilli ince ayar yaparken, iÅŸlemciyi Ã¶rneklendirirken \"dil\" ve \"gÃ¶rev\" ayarlarÄ±nÄ± yapmamÄ±z gerekir. \"Dil\" kaynak ses diline, gÃ¶rev ise konuÅŸma tanÄ±ma iÃ§in \"transcribe\" veya konuÅŸma Ã§evirisi iÃ§in \"translate\" olarak ayarlanmalÄ±dÄ±r. Bu argÃ¼manlar tokenizer'Ä±n davranÄ±ÅŸÄ±nÄ± deÄŸiÅŸtirir ve hedef etiketlerin dÃ¼zgÃ¼n kodlandÄ±ÄŸÄ±ndan emin olmak iÃ§in doÄŸru ÅŸekilde ayarlanmalÄ±dÄ±r.\n\nDil listesini iÃ§e aktararak Whisper tarafÄ±ndan desteklenen tÃ¼m olasÄ± dilleri gÃ¶rebiliriz:","metadata":{}},{"cell_type":"code","source":"from transformers.models.whisper.tokenization_whisper import TO_LANGUAGE_CODE\n\nTO_LANGUAGE_CODE","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:55:56.958809Z","iopub.execute_input":"2024-08-15T04:55:56.959073Z","iopub.status.idle":"2024-08-15T04:56:05.443976Z","shell.execute_reply.started":"2024-08-15T04:55:56.959049Z","shell.execute_reply":"2024-08-15T04:56:05.443089Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'english': 'en',\n 'chinese': 'zh',\n 'german': 'de',\n 'spanish': 'es',\n 'russian': 'ru',\n 'korean': 'ko',\n 'french': 'fr',\n 'japanese': 'ja',\n 'portuguese': 'pt',\n 'turkish': 'tr',\n 'polish': 'pl',\n 'catalan': 'ca',\n 'dutch': 'nl',\n 'arabic': 'ar',\n 'swedish': 'sv',\n 'italian': 'it',\n 'indonesian': 'id',\n 'hindi': 'hi',\n 'finnish': 'fi',\n 'vietnamese': 'vi',\n 'hebrew': 'he',\n 'ukrainian': 'uk',\n 'greek': 'el',\n 'malay': 'ms',\n 'czech': 'cs',\n 'romanian': 'ro',\n 'danish': 'da',\n 'hungarian': 'hu',\n 'tamil': 'ta',\n 'norwegian': 'no',\n 'thai': 'th',\n 'urdu': 'ur',\n 'croatian': 'hr',\n 'bulgarian': 'bg',\n 'lithuanian': 'lt',\n 'latin': 'la',\n 'maori': 'mi',\n 'malayalam': 'ml',\n 'welsh': 'cy',\n 'slovak': 'sk',\n 'telugu': 'te',\n 'persian': 'fa',\n 'latvian': 'lv',\n 'bengali': 'bn',\n 'serbian': 'sr',\n 'azerbaijani': 'az',\n 'slovenian': 'sl',\n 'kannada': 'kn',\n 'estonian': 'et',\n 'macedonian': 'mk',\n 'breton': 'br',\n 'basque': 'eu',\n 'icelandic': 'is',\n 'armenian': 'hy',\n 'nepali': 'ne',\n 'mongolian': 'mn',\n 'bosnian': 'bs',\n 'kazakh': 'kk',\n 'albanian': 'sq',\n 'swahili': 'sw',\n 'galician': 'gl',\n 'marathi': 'mr',\n 'punjabi': 'pa',\n 'sinhala': 'si',\n 'khmer': 'km',\n 'shona': 'sn',\n 'yoruba': 'yo',\n 'somali': 'so',\n 'afrikaans': 'af',\n 'occitan': 'oc',\n 'georgian': 'ka',\n 'belarusian': 'be',\n 'tajik': 'tg',\n 'sindhi': 'sd',\n 'gujarati': 'gu',\n 'amharic': 'am',\n 'yiddish': 'yi',\n 'lao': 'lo',\n 'uzbek': 'uz',\n 'faroese': 'fo',\n 'haitian creole': 'ht',\n 'pashto': 'ps',\n 'turkmen': 'tk',\n 'nynorsk': 'nn',\n 'maltese': 'mt',\n 'sanskrit': 'sa',\n 'luxembourgish': 'lb',\n 'myanmar': 'my',\n 'tibetan': 'bo',\n 'tagalog': 'tl',\n 'malagasy': 'mg',\n 'assamese': 'as',\n 'tatar': 'tt',\n 'hawaiian': 'haw',\n 'lingala': 'ln',\n 'hausa': 'ha',\n 'bashkir': 'ba',\n 'javanese': 'jw',\n 'sundanese': 'su',\n 'cantonese': 'yue',\n 'burmese': 'my',\n 'valencian': 'ca',\n 'flemish': 'nl',\n 'haitian': 'ht',\n 'letzeburgesch': 'lb',\n 'pushto': 'ps',\n 'panjabi': 'pa',\n 'moldavian': 'ro',\n 'moldovan': 'ro',\n 'sinhalese': 'si',\n 'castilian': 'es',\n 'mandarin': 'zh'}"},"metadata":{}}]},{"cell_type":"markdown","source":"Bu listede gezinirseniz, birÃ§ok dilin mevcut olduÄŸunu, ancak Dhivehi'nin mevcut olmayan birkaÃ§ dilden biri olduÄŸunu fark edeceksiniz! Bu, Whisper'Ä±n Dhivehi Ã¼zerinde Ã¶nceden eÄŸitilmediÄŸi anlamÄ±na gelir. Ancak bu, Whisper Ã¼zerinde ince ayar yapamayacaÄŸÄ±mÄ±z anlamÄ±na gelmez. Bunu yaparken, Whisper'a Ã¶nceden eÄŸitilmiÅŸ kontrol noktasÄ±nÄ±n desteklemediÄŸi yeni bir dil Ã¶ÄŸreteceÄŸiz. Bu oldukÃ§a havalÄ±, deÄŸil mi!\n\nYeni bir dilde ince ayar yaptÄ±ÄŸÄ±nÄ±zda, Whisper Ã¶nceden eÄŸitildiÄŸi diÄŸer 96 dil hakkÄ±ndaki bilgisinden yararlanma konusunda iyi bir iÅŸ Ã§Ä±karÄ±r. BÃ¼yÃ¼k Ã¶lÃ§Ã¼de konuÅŸursak, tÃ¼m modern diller Whisper'Ä±n zaten bildiÄŸi 96 dilden en az birine dilsel olarak benzer olacaktÄ±r, bu nedenle bu diller arasÄ± bilgi temsili paradigmasÄ±na gireceÄŸiz.\n\nWhisper'a yeni bir dilde ince ayar yapmak iÃ§in yapmamÄ±z gereken ÅŸey, Whisper'Ä±n Ã¶nceden eÄŸitildiÄŸi en benzer dili bulmaktÄ±r. Dhivehi iÃ§in Wikipedia makalesinde Dhivehi'nin Sri Lanka'nÄ±n Sinhalese dili ile yakÄ±ndan iliÅŸkili olduÄŸu belirtilmektedir. Dil kodlarÄ±nÄ± tekrar kontrol edersek, Sinhalese dilinin Whisper dil setinde mevcut olduÄŸunu gÃ¶rebiliriz, bu nedenle dil argÃ¼manÄ±mÄ±zÄ± gÃ¼venle \"sinhalese\" olarak ayarlayabiliriz.\n\nTamamdÄ±r! Ä°ÅŸlemcimizi Ã¶nceden eÄŸitilmiÅŸ kontrol noktasÄ±ndan yÃ¼kleyeceÄŸiz, dili \"sinhalese\" olarak ve gÃ¶revi yukarÄ±da aÃ§Ä±klandÄ±ÄŸÄ± gibi \"transcribe\" olarak ayarlayacaÄŸÄ±z:","metadata":{}},{"cell_type":"code","source":"from transformers import WhisperProcessor\n\nprocessor = WhisperProcessor.from_pretrained(\n    \"openai/whisper-small\", language=\"sinhalese\", task=\"transcribe\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:56:05.446673Z","iopub.execute_input":"2024-08-15T04:56:05.447270Z","iopub.status.idle":"2024-08-15T04:56:10.105792Z","shell.execute_reply.started":"2024-08-15T04:56:05.447243Z","shell.execute_reply":"2024-08-15T04:56:10.104773Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bda26cabedb4c2ba3378913f5e30f79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b380949c6764852b046ef3ad984fc82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dda7d8f114654d7886f6a33579d91b44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2b379b16cfa481ba2044968476eb690"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c9332516b7945ab839b6320cf1de9d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d71aee44fee420398fa66a53cb0240f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afc4cb6432714769a25240ff2cc6cc73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"806d0b8209ba478f95f28ee90d39e6ae"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Ã‡oÄŸu durumda, ince ayar yapmak istediÄŸiniz dilin Ã¶n eÄŸitim dilleri kÃ¼mesinde olduÄŸunu gÃ¶receksiniz, bu durumda dili doÄŸrudan kaynak ses diliniz olarak ayarlayabilirsiniz! Dil (\"English\") ve gÃ¶rev (\"transcribe\") iÃ§in yalnÄ±zca bir seÃ§eneÄŸin bulunduÄŸu yalnÄ±zca Ä°ngilizce ince ayar iÃ§in bu iki argÃ¼manÄ±n da atlanmasÄ± gerektiÄŸini unutmayÄ±n.","metadata":{}},{"cell_type":"markdown","source":"## Pre-Process the Data\n\nVeri kÃ¼mesi Ã¶zelliklerine bir gÃ¶z atalÄ±m. \"Ses\" sÃ¼tununa Ã¶zellikle dikkat edin - bu, ses giriÅŸlerimizin Ã¶rnekleme oranÄ±nÄ± detaylandÄ±rÄ±r:","metadata":{}},{"cell_type":"code","source":"common_voice[\"train\"].features","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:56:10.107042Z","iopub.execute_input":"2024-08-15T04:56:10.107560Z","iopub.status.idle":"2024-08-15T04:56:10.113644Z","shell.execute_reply.started":"2024-08-15T04:56:10.107531Z","shell.execute_reply":"2024-08-15T04:56:10.112785Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'audio': Audio(sampling_rate=48000, mono=True, decode=True, id=None),\n 'sentence': Value(dtype='string', id=None)}"},"metadata":{}}]},{"cell_type":"markdown","source":"GiriÅŸ sesimiz 48kHz'de Ã¶rneklendiÄŸinden, Whisper Ã¶zellik Ã§Ä±karÄ±cÄ±sÄ±na aktarmadan Ã¶nce 16kHz'ye dÃ¼ÅŸÃ¼rmemiz gerekir; 16kHz, Whisper modeli tarafÄ±ndan beklenen Ã¶rnekleme hÄ±zÄ±dÄ±r.\n\nDataset'in cast_column yÃ¶ntemini kullanarak ses giriÅŸlerini doÄŸru Ã¶rnekleme hÄ±zÄ±na ayarlayacaÄŸÄ±z. Bu iÅŸlem sesi yerinde deÄŸiÅŸtirmez, bunun yerine veri kÃ¼melerine yÃ¼klendiklerinde ses Ã¶rneklerini anÄ±nda yeniden Ã¶rneklemeleri iÃ§in sinyal verir:","metadata":{}},{"cell_type":"code","source":"from datasets import Audio\n\nsampling_rate = processor.feature_extractor.sampling_rate\ncommon_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:56:10.114743Z","iopub.execute_input":"2024-08-15T04:56:10.115038Z","iopub.status.idle":"2024-08-15T04:56:10.131685Z","shell.execute_reply.started":"2024-08-15T04:56:10.115010Z","shell.execute_reply":"2024-08-15T04:56:10.130831Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Åimdi verilerimizi modele hazÄ±r hale getirmek iÃ§in bir fonksiyon yazabiliriz:\n\n- sample[\"audio\"] Ã§aÄŸrÄ±sÄ± yaparak ses verilerini Ã¶rnek bazÄ±nda yÃ¼kler ve yeniden Ã¶rneklendiririz. YukarÄ±da aÃ§Ä±klandÄ±ÄŸÄ± gibi, Datasets gerekli yeniden Ã¶rnekleme iÅŸlemlerini anÄ±nda gerÃ§ekleÅŸtirir.\n- Log-mel spektrogram giriÅŸ Ã¶zelliklerini 1 boyutlu ses dizimizden hesaplamak iÃ§in Ã¶zellik Ã§Ä±karÄ±cÄ±yÄ± kullanÄ±yoruz.\n- TranskripsiyonlarÄ± tokenizer kullanarak etiket kimliklerine kodluyoruz.","metadata":{}},{"cell_type":"code","source":"def prepare_dataset(example):\n    audio = example[\"audio\"]\n\n    example = processor(\n        audio=audio[\"array\"],\n        sampling_rate=audio[\"sampling_rate\"],\n        text=example[\"sentence\"],\n    )\n    \n    example[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:56:10.132957Z","iopub.execute_input":"2024-08-15T04:56:10.133761Z","iopub.status.idle":"2024-08-15T04:56:10.141066Z","shell.execute_reply.started":"2024-08-15T04:56:10.133725Z","shell.execute_reply":"2024-08-15T04:56:10.140216Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"common_voice = common_voice.map(\n    prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=1\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:56:10.142187Z","iopub.execute_input":"2024-08-15T04:56:10.142473Z","iopub.status.idle":"2024-08-15T04:59:10.147169Z","shell.execute_reply.started":"2024-08-15T04:56:10.142449Z","shell.execute_reply":"2024-08-15T04:59:10.146258Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4904 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88d3ea6665764bc5a8686f2729a43933"}},"metadata":{}},{"name":"stderr","text":"2024-08-15 04:56:27.137746: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-15 04:56:27.138068: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-15 04:56:27.306280: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2212 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a17b7ad2cc14529aa63fedf72ffaf5a"}},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 30.0\n\ndef is_audio_in_length_range(length):\n    return length < max_input_length\n\ncommon_voice[\"train\"] = common_voice[\"train\"].filter(\n    is_audio_in_length_range,\n    input_columns=[\"input_length\"],\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:10.148288Z","iopub.execute_input":"2024-08-15T04:59:10.148953Z","iopub.status.idle":"2024-08-15T04:59:10.186986Z","shell.execute_reply.started":"2024-08-15T04:59:10.148925Z","shell.execute_reply":"2024-08-15T04:59:10.186142Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/4904 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7e71a9fba2340819fe2ac9ba8b1537e"}},"metadata":{}}]},{"cell_type":"code","source":"common_voice[\"train\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:10.189914Z","iopub.execute_input":"2024-08-15T04:59:10.190188Z","iopub.status.idle":"2024-08-15T04:59:14.284122Z","shell.execute_reply.started":"2024-08-15T04:59:10.190163Z","shell.execute_reply":"2024-08-15T04:59:14.283224Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_features', 'labels', 'input_length'],\n    num_rows: 4904\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"Bu durumda aslÄ±nda daha Ã¶nce olduÄŸu gibi aynÄ± sayÄ±da Ã¶rneÄŸe sahibiz, yani 30 saniyeden uzun Ã¶rnek yok. Dil deÄŸiÅŸtirdiÄŸinizde durum bÃ¶yle olmayabilir, bu nedenle saÄŸlamlÄ±k iÃ§in bu filtre adÄ±mÄ±nÄ± yerinde tutmak en iyisidir. Bununla birlikte, verilerimiz eÄŸitim iÃ§in tamamen hazÄ±r! Devam edelim ve Whisper'a ince ayar yapmak iÃ§in bu verileri nasÄ±l kullanabileceÄŸimize bir gÃ¶z atalÄ±m.","metadata":{}},{"cell_type":"markdown","source":"## Training and Evaluation\n\nVerilerimizi hazÄ±rladÄ±ÄŸÄ±mÄ±za gÃ¶re artÄ±k eÄŸitim hattÄ±na dalmaya hazÄ±rÄ±z. Trainer bizim iÃ§in aÄŸÄ±r iÅŸlerin Ã§oÄŸunu yapacaktÄ±r. Tek yapmamÄ±z gereken\n\n- Bir veri harmanlayÄ±cÄ± tanÄ±mlamak: veri harmanlayÄ±cÄ± Ã¶nceden iÅŸlenmiÅŸ verilerimizi alÄ±r ve PyTorch tensÃ¶rlerini model iÃ§in hazÄ±rlar.\n\n- DeÄŸerlendirme metrikleri: DeÄŸerlendirme sÄ±rasÄ±nda, modeli kelime hata oranÄ± (WER) metriÄŸini kullanarak deÄŸerlendirmek istiyoruz. Bu hesaplamayÄ± gerÃ§ekleÅŸtiren bir compute_metrics fonksiyonu tanÄ±mlamamÄ±z gerekiyor.\n\n- Ã–nceden eÄŸitilmiÅŸ bir kontrol noktasÄ± yÃ¼kleyin: Ã¶nceden eÄŸitilmiÅŸ bir kontrol noktasÄ± yÃ¼klememiz ve eÄŸitim iÃ§in doÄŸru ÅŸekilde yapÄ±landÄ±rmamÄ±z gerekir.\n\n- EÄŸitim argÃ¼manlarÄ±nÄ± tanÄ±mlayÄ±n: bunlar Trainer tarafÄ±ndan eÄŸitim programÄ±nÄ± oluÅŸtururken kullanÄ±lacaktÄ±r.\n\nModele ince ayar yaptÄ±ktan sonra, Dhivehi dilinde konuÅŸmayÄ± yazÄ±ya dÃ¶kmek Ã¼zere doÄŸru ÅŸekilde eÄŸittiÄŸimizi doÄŸrulamak iÃ§in test verileri Ã¼zerinde deÄŸerlendireceÄŸiz.","metadata":{}},{"cell_type":"markdown","source":"### Define a Data Collator\n\nBir diziden diziye konuÅŸma modeli iÃ§in veri harmanlayÄ±cÄ±, input_features ve label'larÄ± baÄŸÄ±msÄ±z olarak ele almasÄ± bakÄ±mÄ±ndan benzersizdir: input_features feature extractor tarafÄ±ndan, label'lar ise tokenizer tarafÄ±ndan ele alÄ±nmalÄ±dÄ±r.\n\nInput_features zaten 30'lara dolgulanmÄ±ÅŸ ve sabit boyutlu bir log-Mel spektrogramÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r, bu nedenle tek yapmamÄ±z gereken onlarÄ± toplu PyTorch tensÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rmektir. Bunu return_tensors=pt ile Ã¶zellik Ã§Ä±karÄ±cÄ±nÄ±n .pad yÃ¶ntemini kullanarak yapÄ±yoruz. Girdiler sabit boyutlu olduÄŸu iÃ§in burada ek bir dolgu uygulanmadÄ±ÄŸÄ±na dikkat edin, input_features basitÃ§e PyTorch tensÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.\n\nÃ–te yandan, etiketler dolgusuzdur. Ä°lk olarak tokenizer'Ä±n .pad yÃ¶ntemini kullanarak dizileri yÄ±ÄŸÄ±ndaki maksimum uzunluÄŸa kadar dolduruyoruz. Dolgu belirteÃ§leri daha sonra -100 ile deÄŸiÅŸtirilir, bÃ¶ylece kayÄ±p hesaplanÄ±rken bu belirteÃ§ler dikkate alÄ±nmaz. Daha sonra eÄŸitim sÄ±rasÄ±nda eklediÄŸimiz transkript belirtecinin baÅŸlangÄ±cÄ±nÄ± etiket dizisinin baÅŸÄ±ndan kesiyoruz.\n\nHem Ã¶zellik Ã§Ä±karÄ±cÄ± hem de tokenizer iÅŸlemlerini gerÃ§ekleÅŸtirmek iÃ§in daha Ã¶nce tanÄ±mladÄ±ÄŸÄ±mÄ±z WhisperProcessor'dan faydalanabiliriz:","metadata":{}},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\n\n@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n    \n    def __call__(\n        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]\n    ) -> Dict[str, torch.Tensor]:\n        input_features = [\n            {\"input_features\": feature[\"input_features\"][0]} for feature in features\n        ]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n        labels = labels_batch[\"input_ids\"].masked_fill(\n            labels_batch.attention_mask.ne(1), -100\n        )\n        \n        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n        \n        batch[\"labels\"] = labels\n        \n        return batch","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:14.285387Z","iopub.execute_input":"2024-08-15T04:59:14.285660Z","iopub.status.idle":"2024-08-15T04:59:14.296282Z","shell.execute_reply.started":"2024-08-15T04:59:14.285636Z","shell.execute_reply":"2024-08-15T04:59:14.295564Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:14.297344Z","iopub.execute_input":"2024-08-15T04:59:14.297647Z","iopub.status.idle":"2024-08-15T04:59:14.312233Z","shell.execute_reply.started":"2024-08-15T04:59:14.297622Z","shell.execute_reply":"2024-08-15T04:59:14.311365Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation Metrics\n\nArdÄ±ndan, deÄŸerlendirme setimizde kullanacaÄŸÄ±mÄ±z deÄŸerlendirme metriÄŸini tanÄ±mlÄ±yoruz. ASR sistemlerini deÄŸerlendirmek iÃ§in 'de-facto' metrik olan DeÄŸerlendirme bÃ¶lÃ¼mÃ¼nde tanÄ±tÄ±lan Kelime Hata OranÄ± (WER) metriÄŸini kullanacaÄŸÄ±z.","metadata":{}},{"cell_type":"code","source":"!pip install -q evaluate jiwer","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:14.313367Z","iopub.execute_input":"2024-08-15T04:59:14.313788Z","iopub.status.idle":"2024-08-15T04:59:29.907333Z","shell.execute_reply.started":"2024-08-15T04:59:14.313755Z","shell.execute_reply":"2024-08-15T04:59:29.906343Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Daha sonra model tahminlerimizi alan ve WER metriÄŸini dÃ¶ndÃ¼ren bir fonksiyon tanÄ±mlamamÄ±z yeterlidir. compute_metrics adÄ± verilen bu fonksiyon, ilk olarak label_ids'deki pad_token_id ile -100'Ã¼ deÄŸiÅŸtirir (kayÄ±pta dolgulu belirteÃ§leri doÄŸru ÅŸekilde yok saymak iÃ§in veri harmanlayÄ±cÄ±da uyguladÄ±ÄŸÄ±mÄ±z adÄ±mÄ± geri alÄ±r). Daha sonra tahmin edilen ve etiket kimliklerini dizelere Ã§Ã¶zer. Son olarak, tahminler ve referans etiketleri arasÄ±ndaki WER deÄŸerini hesaplar. Burada, noktalama iÅŸaretleri ve bÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harfler kaldÄ±rÄ±lmÄ±ÅŸ 'normalleÅŸtirilmiÅŸ' transkripsiyonlar ve tahminlerle deÄŸerlendirme seÃ§eneÄŸimiz vardÄ±r. TranskripsiyonlarÄ± normalleÅŸtirerek elde edilen WER iyileÅŸtirmesinden yararlanmak iÃ§in bunu izlemenizi Ã¶neririz.","metadata":{}},{"cell_type":"code","source":"import evaluate\nfrom transformers.models.whisper.english_normalizer import BasicTextNormalizer\n\n\nmetric = evaluate.load(\"wer\")\nnormalizer = BasicTextNormalizer()\n\ndef compute_metrics(pred):\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n    \n    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n    \n    wer_ortho = 100 * metric.compute(predictions=pred_str, references=label_str)\n    \n    pred_str_norm = [normalizer(pred) for pred in pred_str]\n    label_str_norm = [normalizer(label) for label in label_str]\n    \n    pred_str_norm = [\n        pred_str_norm[i] for i in range(len(pred_str_norm)) if len(label_str_norm[i]) > 0\n    ]\n    label_str_norm = [\n        label_str_norm[i]\n        for i in range(len(label_str_norm))\n        if len(label_str_norm[i]) > 0\n    ]\n    \n    wer = 100 * metric.compute(predictions=pred_str_norm, references=label_str_norm)\n\n    return {\"wer_ortho\": wer_ortho, \"wer\": wer}","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:29.909047Z","iopub.execute_input":"2024-08-15T04:59:29.909435Z","iopub.status.idle":"2024-08-15T04:59:30.966775Z","shell.execute_reply.started":"2024-08-15T04:59:29.909405Z","shell.execute_reply":"2024-08-15T04:59:30.965886Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cc8b7d711174baaa833ea15e266eae3"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import WhisperForConditionalGeneration\n\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:30.967916Z","iopub.execute_input":"2024-08-15T04:59:30.968175Z","iopub.status.idle":"2024-08-15T04:59:35.549834Z","shell.execute_reply.started":"2024-08-15T04:59:30.968152Z","shell.execute_reply":"2024-08-15T04:59:35.549068Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d92eb3e7f23f4ccb89570ce10c1b1d5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bd05d40b97a4fe0a25c824c58fd2e44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/3.87k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fddf6017cf440f0885259050f9a722d"}},"metadata":{}}]},{"cell_type":"markdown","source":"Gradyan kontrol noktasÄ± kullandÄ±ÄŸÄ±mÄ±z ve ikisi uyumsuz olduÄŸu iÃ§in `use_cache`'i eÄŸitim iÃ§in **False** olarak ayarlayacaÄŸÄ±z. AyrÄ±ca Ã§Ä±karÄ±m sÄ±rasÄ±nda modelin davranÄ±ÅŸÄ±nÄ± kontrol etmek iÃ§in iki Ã¼retim argÃ¼manÄ±nÄ± geÃ§ersiz kÄ±lacaÄŸÄ±z: dil ve gÃ¶rev argÃ¼manlarÄ±nÄ± ayarlayarak Ã¼retim sÄ±rasÄ±nda dil ve gÃ¶rev belirteÃ§lerini zorlayacaÄŸÄ±z ve ayrÄ±ca Ã§Ä±karÄ±m sÃ¼resini hÄ±zlandÄ±rmak iÃ§in Ã¼retim iÃ§in Ã¶nbelleÄŸi yeniden etkinleÅŸtireceÄŸiz:","metadata":{}},{"cell_type":"code","source":"from functools import partial\n\n# gradyan kontrol noktasÄ± ile uyumsuz olduÄŸu iÃ§in eÄŸitim sÄ±rasÄ±nda Ã¶nbelleÄŸi devre dÄ±ÅŸÄ± bÄ±rakÄ±n\nmodel.config.use_cache = False\n\n# Ã¼retim iÃ§in dili ve gÃ¶revi ayarlayÄ±n ve Ã¶nbelleÄŸi yeniden etkinleÅŸtirin\nmodel.generate = partial(\n    model.generate, language=\"sinhalese\", task=\"transcribe\", use_cache=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:35.551033Z","iopub.execute_input":"2024-08-15T04:59:35.551327Z","iopub.status.idle":"2024-08-15T04:59:35.556366Z","shell.execute_reply.started":"2024-08-15T04:59:35.551286Z","shell.execute_reply":"2024-08-15T04:59:35.555429Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./whisper-small-dv\",\n    per_device_train_batch_size=8,\n    gradient_accumulation_steps=4,\n    learning_rate=1e-5,\n    lr_scheduler_type=\"constant_with_warmup\",\n    warmup_steps=50,\n    max_steps=500,\n    gradient_checkpointing=True,\n    fp16=True,\n    fp16_full_eval=True,\n    evaluation_strategy=\"steps\",\n    per_device_eval_batch_size=8,\n    predict_with_generate=True,\n    generation_max_length=225,\n    save_steps=250,\n    eval_steps=250,\n    logging_steps=50,\n    report_to=[\"tensorboard\"],\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:35.557564Z","iopub.execute_input":"2024-08-15T04:59:35.557829Z","iopub.status.idle":"2024-08-15T04:59:35.964449Z","shell.execute_reply.started":"2024-08-15T04:59:35.557807Z","shell.execute_reply":"2024-08-15T04:59:35.963457Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=common_voice[\"train\"],\n    eval_dataset=common_voice[\"test\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=processor,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:35.965617Z","iopub.execute_input":"2024-08-15T04:59:35.965918Z","iopub.status.idle":"2024-08-15T04:59:36.595681Z","shell.execute_reply.started":"2024-08-15T04:59:35.965892Z","shell.execute_reply":"2024-08-15T04:59:36.594786Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:59:36.596958Z","iopub.execute_input":"2024-08-15T04:59:36.597321Z","iopub.status.idle":"2024-08-15T08:36:13.530280Z","shell.execute_reply.started":"2024-08-15T04:59:36.597272Z","shell.execute_reply":"2024-08-15T08:36:13.529387Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [500/500 3:35:50, Epoch 3/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Wer Ortho</th>\n      <th>Wer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>250</td>\n      <td>0.185800</td>\n      <td>0.203400</td>\n      <td>69.691483</td>\n      <td>15.810064</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.074700</td>\n      <td>0.166556</td>\n      <td>60.247928</td>\n      <td>12.868171</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\nThere were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=500, training_loss=0.7941111783981323, metrics={'train_runtime': 12969.1672, 'train_samples_per_second': 1.234, 'train_steps_per_second': 0.039, 'total_flos': 4.61736640512e+18, 'train_loss': 0.7941111783981323, 'epoch': 3.262642740619902})"},"metadata":{}}]},{"cell_type":"code","source":"kwargs = {\n    \"dataset_tags\": \"mozilla-foundation/common_voice_13_0\",\n    \"dataset\": \"Common Voice 13\",\n    \"language\": \"dv\",\n    \"model_name\": \"Whisper-Small-Dv-fine-tuned\",\n    \"finetuned_from\": \"openai/whisper-small\",\n    \"tasks\": \"automatic-speech-recognition\",\n}\n\ntrainer.push_to_hub(**kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T08:36:13.531485Z","iopub.execute_input":"2024-08-15T08:36:13.531792Z","iopub.status.idle":"2024-08-15T08:36:21.033413Z","shell.execute_reply.started":"2024-08-15T08:36:13.531763Z","shell.execute_reply":"2024-08-15T08:36:21.032456Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Leotrim/whisper-small-dv/commit/2c156254258472e3d93d70a389f2146aaf3c86f2', commit_message='End of training', commit_description='', oid='2c156254258472e3d93d70a389f2146aaf3c86f2', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}